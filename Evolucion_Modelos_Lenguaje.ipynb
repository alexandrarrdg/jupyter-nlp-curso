{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìñ Evoluci√≥n de los Modelos de Lenguaje\n",
    "## De NLP Cl√°sico a Modelos Generativos Modernos\n",
    "\n",
    "**Curso Universitario - Procesamiento de Lenguaje Natural**\n",
    "\n",
    "---\n",
    "\n",
    "### Objetivos de aprendizaje:\n",
    "\n",
    "1. Comprender la evoluci√≥n hist√≥rica del NLP\n",
    "2. Practicar t√©cnicas cl√°sicas: tokenizaci√≥n, TF-IDF, n-gramas\n",
    "3. Trabajar con embeddings modernos\n",
    "4. Experimentar con modelos transformer (BERT, GPT)\n",
    "5. Aplicar t√©cnicas avanzadas: prompt engineering, RAG, agentes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducci√≥n y Contexto\n",
    "\n",
    "### ¬øQu√© es el Procesamiento de Lenguaje Natural (NLP)?\n",
    "\n",
    "El **Procesamiento de Lenguaje Natural** (Natural Language Processing, NLP) es el campo de la inteligencia artificial que permite a las m√°quinas:\n",
    "\n",
    "- **Entender** el lenguaje humano (comprensi√≥n)\n",
    "- **Generar** texto coherente y relevante (generaci√≥n)\n",
    "- **Extraer** informaci√≥n significativa de textos\n",
    "- **Traducir** entre idiomas\n",
    "- **Analizar** sentimientos, intenciones y contexto\n",
    "\n",
    "### ¬øPor qu√© es importante?\n",
    "\n",
    "- El 80% de los datos empresariales son no estructurados (textos, emails, documentos)\n",
    "- Permite automatizar tareas que antes requer√≠an comprensi√≥n humana\n",
    "- Aplicaciones: chatbots, traducci√≥n autom√°tica, an√°lisis de redes sociales, asistentes virtuales\n",
    "- Base de sistemas como ChatGPT, Google Translate, Siri, Alexa\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Evoluci√≥n Hist√≥rica del NLP\n",
    "\n",
    "#### **1. Era de las Reglas (1950-1990)**\n",
    "- **Enfoque**: Gram√°ticas formales, sistemas basados en reglas escritas a mano\n",
    "- **Ejemplo**: ELIZA (1966), primer chatbot con reglas if-then\n",
    "- **Limitaciones**: No escalables, fr√°giles ante variaciones del lenguaje\n",
    "\n",
    "#### **2. Era Estad√≠stica (1990-2010)**\n",
    "- **Enfoque**: Modelos probabil√≠sticos, n-gramas, Bag of Words, TF-IDF\n",
    "- **T√©cnicas**: Naive Bayes, HMM (Hidden Markov Models), CRF\n",
    "- **Ventajas**: Aprenden de datos, m√°s robustos\n",
    "- **Limitaciones**: No capturan sem√°ntica profunda ni contexto largo\n",
    "\n",
    "#### **3. Era del Deep Learning (2010-2017)**\n",
    "- **Enfoque**: Redes neuronales: RNN, LSTM, GRU\n",
    "- **Hito**: Word2Vec (2013), GloVe (2014) - embeddings que capturan sem√°ntica\n",
    "- **Ventajas**: Capturan contexto secuencial\n",
    "- **Limitaciones**: Problema del gradiente desvaneciente, lentitud en secuencias largas\n",
    "\n",
    "#### **4. Era de los Transformers (2017-2020)**\n",
    "- **Hito**: Paper \"Attention Is All You Need\" (2017)\n",
    "- **Modelos**: BERT (2018), GPT-2 (2019), RoBERTa, T5\n",
    "- **Innovaci√≥n**: Mecanismo de atenci√≥n, procesamiento paralelo\n",
    "- **Ventajas**: Capturan contexto bidireccional, escalan mejor\n",
    "\n",
    "#### **5. Era de los LLM - Modelos Generativos (2020-actualidad)**\n",
    "- **Modelos**: GPT-3/4 (OpenAI), LLaMA (Meta), Claude (Anthropic), Gemini (Google)\n",
    "- **Caracter√≠sticas**: \n",
    "  - Billones de par√°metros\n",
    "  - Entrenamiento con billones de tokens\n",
    "  - Capacidades emergentes (razonamiento, c√≥digo, multimodalidad)\n",
    "- **T√©cnicas**: Prompt engineering, RAG, fine-tuning, agentes\n",
    "\n",
    "---\n",
    "\n",
    "### Tabla Comparativa\n",
    "\n",
    "| Era | T√©cnica Principal | Fortaleza | Debilidad |\n",
    "|-----|-------------------|-----------|----------|\n",
    "| Reglas | Gram√°ticas manuales | Precisi√≥n en casos espec√≠ficos | No escala, inflexible |\n",
    "| Estad√≠stica | N-gramas, TF-IDF | Aprende de datos | No captura sem√°ntica |\n",
    "| Deep Learning | RNN, LSTM | Contexto secuencial | Lento, memoria limitada |\n",
    "| Transformers | Attention mechanism | Contexto largo, paralelo | Requiere muchos datos |\n",
    "| LLMs | Modelos masivos | Capacidades generales | Costoso, alucinaciones |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 1: Reflexi√≥n sobre NLP en tu vida cotidiana\n",
    "\n",
    "**Instrucciones**: Piensa en al menos **5 ejemplos** de aplicaciones de NLP que uses en tu d√≠a a d√≠a. Escr√≠belos en la lista de Python a continuaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Completa esta lista con 5 ejemplos de NLP que uses diariamente\n",
    "# Ejemplos: \"Autocorrector del m√≥vil\", \"Google Translate\", \"ChatGPT\", etc.\n",
    "\n",
    "mis_ejemplos_nlp = [\n",
    "    # Escribe tus 5 ejemplos aqu√≠:\n",
    "    \n",
    "]\n",
    "\n",
    "# Imprimimos la lista\n",
    "print(\"ü§ñ Aplicaciones de NLP en mi vida cotidiana:\\n\")\n",
    "for i, ejemplo in enumerate(mis_ejemplos_nlp, 1):\n",
    "    print(f\"{i}. {ejemplo}\")\n",
    "\n",
    "print(f\"\\nüìä Total de aplicaciones identificadas: {len(mis_ejemplos_nlp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Preprocesamiento B√°sico y An√°lisis Ling√º√≠stico (NLP Cl√°sico)\n",
    "\n",
    "### Fundamentos del NLP Cl√°sico\n",
    "\n",
    "Antes de los modelos modernos, el procesamiento de texto requer√≠a m√∫ltiples pasos de preprocesamiento:\n",
    "\n",
    "#### **Tokenizaci√≥n**\n",
    "Dividir el texto en unidades b√°sicas (palabras, oraciones)\n",
    "- Ejemplo: `\"Hola mundo\"` ‚Üí `[\"Hola\", \"mundo\"]`\n",
    "\n",
    "#### **Stopwords (palabras vac√≠as)**\n",
    "Eliminar palabras comunes sin significado relevante\n",
    "- Ejemplo: \"el\", \"la\", \"de\", \"que\", \"y\"\n",
    "\n",
    "#### **Stemming (derivaci√≥n)**\n",
    "Reducir palabras a su ra√≠z eliminando sufijos\n",
    "- Ejemplo: `\"corriendo\"` ‚Üí `\"corr\"`\n",
    "- M√°s r√°pido pero menos preciso\n",
    "\n",
    "#### **Lematizaci√≥n**\n",
    "Reducir palabras a su forma can√≥nica (lema) usando an√°lisis ling√º√≠stico\n",
    "- Ejemplo: `\"corriendo\"` ‚Üí `\"correr\"`\n",
    "- M√°s lento pero m√°s preciso\n",
    "\n",
    "#### **N-gramas**\n",
    "Secuencias consecutivas de N palabras\n",
    "- 1-grama (unigrama): `[\"el\", \"gato\", \"negro\"]`\n",
    "- 2-grama (bigrama): `[\"el gato\", \"gato negro\"]`\n",
    "- 3-grama (trigrama): `[\"el gato negro\"]`\n",
    "\n",
    "### ¬øPor qu√© fueron importantes?\n",
    "\n",
    "- Reducen la dimensionalidad del vocabulario\n",
    "- Normalizan variaciones morfol√≥gicas\n",
    "- Permiten enfocarse en palabras significativas\n",
    "- Base para modelos estad√≠sticos (Naive Bayes, clasificadores)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos las librer√≠as necesarias\n",
    "!pip install -q spacy nltk\n",
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "modelo_embeddings = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "print(\"Dimensi√≥n:\", modelo_embeddings.get_sentence_embedding_dimension())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Descargamos recursos de NLTK\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Cargamos el modelo de espa√±ol de spaCy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "print(\"‚úÖ Librer√≠as cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto de ejemplo para analizar\n",
    "texto = \"\"\"\n",
    "El procesamiento del lenguaje natural es una disciplina fascinante que combina \n",
    "la ling√º√≠stica computacional con la inteligencia artificial. Los investigadores \n",
    "est√°n desarrollando sistemas cada vez m√°s sofisticados para analizar, comprender \n",
    "y generar lenguaje humano. Estos sistemas procesan millones de textos y aprenden \n",
    "patrones ling√º√≠sticos complejos.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìù Texto original:\")\n",
    "print(texto.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizaci√≥n con spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos el texto con spaCy\n",
    "doc = nlp(texto)\n",
    "\n",
    "# Extraemos tokens (palabras)\n",
    "tokens = [token.text for token in doc]\n",
    "\n",
    "print(\"üî§ Tokens extra√≠dos:\")\n",
    "print(tokens)\n",
    "print(f\"\\nüìä Total de tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminaci√≥n de stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las stopwords en espa√±ol\n",
    "stop_words_es = set(stopwords.words('spanish'))\n",
    "\n",
    "# Filtramos tokens que no sean stopwords ni puntuaci√≥n\n",
    "tokens_filtrados = [\n",
    "    token.text.lower() \n",
    "    for token in doc \n",
    "    if token.text.lower() not in stop_words_es \n",
    "    and token.is_alpha  # Solo palabras (no puntuaci√≥n)\n",
    "]\n",
    "\n",
    "print(\"üßπ Tokens despu√©s de eliminar stopwords:\")\n",
    "print(tokens_filtrados)\n",
    "print(f\"\\nüìä Tokens originales: {len(tokens)} ‚Üí Tokens filtrados: {len(tokens_filtrados)}\")\n",
    "print(f\"Reducci√≥n: {(1 - len(tokens_filtrados)/len(tokens)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lematizaci√≥n con spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lematizaci√≥n: reducimos cada palabra a su forma base\n",
    "lemas = [token.lemma_ for token in doc if token.is_alpha and token.text.lower() not in stop_words_es]\n",
    "\n",
    "print(\"üìö Comparaci√≥n Token ‚Üí Lema:\\n\")\n",
    "comparacion = [(token.text, token.lemma_) for token in doc if token.is_alpha][:15]\n",
    "\n",
    "for token, lema in comparacion:\n",
    "    if token.lower() != lema.lower():\n",
    "        print(f\"  {token:20} ‚Üí {lema}\")\n",
    "    else:\n",
    "        print(f\"  {token:20} (sin cambio)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis de frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos las palabras m√°s frecuentes\n",
    "frecuencias = Counter(lemas)\n",
    "mas_comunes = frecuencias.most_common(10)\n",
    "\n",
    "print(\"üìä Top 10 palabras m√°s frecuentes (lematizadas):\\n\")\n",
    "for palabra, freq in mas_comunes:\n",
    "    print(f\"  {palabra:20} {freq:3} veces {'‚ñà' * freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generaci√≥n de N-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_ngramas(tokens, n):\n",
    "    \"\"\"Genera n-gramas a partir de una lista de tokens\"\"\"\n",
    "    ngramas = []\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngrama = ' '.join(tokens[i:i+n])\n",
    "        ngramas.append(ngrama)\n",
    "    return ngramas\n",
    "\n",
    "# Generamos bigramas y trigramas\n",
    "bigramas = generar_ngramas(tokens_filtrados, 2)\n",
    "trigramas = generar_ngramas(tokens_filtrados, 3)\n",
    "\n",
    "print(\"üìå Ejemplos de Bigramas (2-gramas):\\n\")\n",
    "for bg in bigramas[:10]:\n",
    "    print(f\"  ‚Ä¢ {bg}\")\n",
    "\n",
    "print(\"\\nüìå Ejemplos de Trigramas (3-gramas):\\n\")\n",
    "for tg in trigramas[:8]:\n",
    "    print(f\"  ‚Ä¢ {tg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üìù EJERCICIO 2: Stemming vs Lematizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Implementa stemming y comp√°ralo con lematizaci√≥n\n",
    "\n",
    "# Palabras de prueba\n",
    "palabras_prueba = [\n",
    "    \"corriendo\", \"corri√≥\", \"correr\", \"corredor\",\n",
    "    \"desarrollando\", \"desarrolladores\", \"desarrollo\",\n",
    "    \"sistemas\", \"sistem√°tico\", \"sistematizaci√≥n\"\n",
    "]\n",
    "\n",
    "# Inicializamos el stemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "print(\"üîç Comparaci√≥n Stemming vs Lematizaci√≥n:\\n\")\n",
    "print(f\"{'Palabra Original':<25} {'Stemming':<20} {'Lematizaci√≥n':<20}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for palabra in palabras_prueba:\n",
    "    # Aplicamos stemming\n",
    "    stem = stemmer.stem(palabra)\n",
    "    \n",
    "    # Aplicamos lematizaci√≥n\n",
    "    doc_temp = nlp(palabra)\n",
    "    lema = doc_temp[0].lemma_\n",
    "    \n",
    "    print(f\"{palabra:<25} {stem:<20} {lema:<20}\")\n",
    "\n",
    "print(\"\\nüí° Observa las diferencias:\")\n",
    "print(\"   - Stemming: m√°s agresivo, puede producir ra√≠ces no v√°lidas\")\n",
    "print(\"   - Lematizaci√≥n: m√°s preciso, produce palabras reales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 3: An√°lisis de N-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Analiza las diferencias entre unigramas, bigramas y trigramas\n",
    "\n",
    "# Generamos los tres tipos de n-gramas\n",
    "unigramas = tokens_filtrados\n",
    "bigramas = generar_ngramas(tokens_filtrados, 2)\n",
    "trigramas = generar_ngramas(tokens_filtrados, 3)\n",
    "\n",
    "# Contamos frecuencias\n",
    "freq_uni = Counter(unigramas)\n",
    "freq_bi = Counter(bigramas)\n",
    "freq_tri = Counter(trigramas)\n",
    "\n",
    "print(\"üìä An√°lisis comparativo de N-gramas\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüîπ Top 5 Unigramas (palabras individuales):\")\n",
    "for ngrama, freq in freq_uni.most_common(5):\n",
    "    print(f\"  {freq}x - {ngrama}\")\n",
    "\n",
    "print(\"\\nüîπ Top 5 Bigramas (pares de palabras):\")\n",
    "for ngrama, freq in freq_bi.most_common(5):\n",
    "    print(f\"  {freq}x - {ngrama}\")\n",
    "\n",
    "print(\"\\nüîπ Top 5 Trigramas (tr√≠os de palabras):\")\n",
    "for ngrama, freq in freq_tri.most_common(5):\n",
    "    print(f\"  {freq}x - {ngrama}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nüí° ¬øQu√© observas?\")\n",
    "print(\"   - Unigramas: palabras aisladas, pierden contexto\")\n",
    "print(\"   - Bigramas: capturan relaciones b√°sicas entre palabras\")\n",
    "print(\"   - Trigramas: m√°s contexto, pero tambi√©n m√°s escasos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 4: Visualizaci√≥n de frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Crea un gr√°fico de barras con las palabras m√°s frecuentes\n",
    "\n",
    "# Obtenemos las 15 palabras m√°s comunes\n",
    "top_palabras = frecuencias.most_common(15)\n",
    "palabras = [p[0] for p in top_palabras]\n",
    "conteos = [p[1] for p in top_palabras]\n",
    "\n",
    "# Creamos el gr√°fico\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(palabras, conteos, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Frecuencia', fontsize=12)\n",
    "plt.ylabel('Palabra (lematizada)', fontsize=12)\n",
    "plt.title('Top 15 Palabras M√°s Frecuentes en el Texto', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()  # Invertir para que la m√°s frecuente est√© arriba\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Gr√°fico generado con las palabras m√°s frecuentes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Representaciones Vectoriales: Bag of Words y TF-IDF\n",
    "\n",
    "### ¬øPor qu√© vectorizar el texto?\n",
    "\n",
    "Los algoritmos de machine learning **no entienden texto**, solo n√∫meros. Necesitamos convertir el texto en vectores num√©ricos.\n",
    "\n",
    "---\n",
    "\n",
    "### **Bag of Words (BoW) - Bolsa de Palabras**\n",
    "\n",
    "**Concepto**: Representar un documento como un vector de frecuencias de palabras, ignorando el orden.\n",
    "\n",
    "**Ejemplo**:\n",
    "```\n",
    "Documento 1: \"el gato come pescado\"\n",
    "Documento 2: \"el perro come carne\"\n",
    "\n",
    "Vocabulario: [el, gato, perro, come, pescado, carne]\n",
    "\n",
    "Doc1: [1, 1, 0, 1, 1, 0]\n",
    "Doc2: [1, 0, 1, 1, 0, 1]\n",
    "```\n",
    "\n",
    "**Ventajas**:\n",
    "- Simple de implementar\n",
    "- Funciona bien para tareas b√°sicas\n",
    "\n",
    "**Limitaciones**:\n",
    "- Pierde el orden de las palabras\n",
    "- No captura significado sem√°ntico\n",
    "- Palabras comunes dominan la representaci√≥n\n",
    "\n",
    "---\n",
    "\n",
    "### **TF-IDF (Term Frequency - Inverse Document Frequency)**\n",
    "\n",
    "**Concepto**: Ponderar las palabras seg√∫n su importancia en el documento y en todo el corpus.\n",
    "\n",
    "**F√≥rmula**:\n",
    "```\n",
    "TF-IDF(palabra, doc) = TF(palabra, doc) √ó IDF(palabra)\n",
    "\n",
    "TF = Frecuencia de la palabra en el documento\n",
    "IDF = log(Total documentos / Documentos que contienen la palabra)\n",
    "```\n",
    "\n",
    "**Intuici√≥n**:\n",
    "- Palabras **frecuentes** en un documento pero **raras** en el corpus ‚Üí **Mayor peso**\n",
    "- Palabras **muy comunes** en todos los documentos ‚Üí **Menor peso**\n",
    "\n",
    "**Ventajas**:\n",
    "- Reduce el peso de palabras comunes\n",
    "- Resalta palabras discriminativas\n",
    "- Mejor para b√∫squeda y clasificaci√≥n\n",
    "\n",
    "**Limitaciones**:\n",
    "- Sigue sin capturar sem√°ntica\n",
    "- Sensible al tama√±o del corpus\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Corpus de ejemplo: documentos sobre diferentes temas\n",
    "corpus = [\n",
    "    \"El aprendizaje autom√°tico es una rama de la inteligencia artificial\",\n",
    "    \"Las redes neuronales profundas son la base del deep learning\",\n",
    "    \"Los modelos de lenguaje procesan y generan texto humano\",\n",
    "    \"El procesamiento de lenguaje natural combina ling√º√≠stica e inteligencia artificial\",\n",
    "    \"Los transformers revolucionaron el procesamiento del lenguaje natural\"\n",
    "]\n",
    "\n",
    "print(\"üìö Corpus de documentos:\\n\")\n",
    "for i, doc in enumerate(corpus, 1):\n",
    "    print(f\"{i}. {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el vectorizador Bag of Words\n",
    "vectorizer_bow = CountVectorizer()\n",
    "\n",
    "# Transformamos el corpus\n",
    "bow_matrix = vectorizer_bow.fit_transform(corpus)\n",
    "\n",
    "# Obtenemos el vocabulario\n",
    "vocabulario = vectorizer_bow.get_feature_names_out()\n",
    "\n",
    "# Convertimos a DataFrame para visualizar mejor\n",
    "df_bow = pd.DataFrame(\n",
    "    bow_matrix.toarray(),\n",
    "    columns=vocabulario,\n",
    "    index=[f\"Doc{i+1}\" for i in range(len(corpus))]\n",
    ")\n",
    "\n",
    "print(\"üéí Matriz Bag of Words:\\n\")\n",
    "print(df_bow)\n",
    "print(f\"\\nüìä Tama√±o del vocabulario: {len(vocabulario)} palabras\")\n",
    "print(f\"üìä Dimensi√≥n de la matriz: {bow_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el vectorizador TF-IDF\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "\n",
    "# Transformamos el corpus\n",
    "tfidf_matrix = vectorizer_tfidf.fit_transform(corpus)\n",
    "\n",
    "# Convertimos a DataFrame\n",
    "df_tfidf = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=vectorizer_tfidf.get_feature_names_out(),\n",
    "    index=[f\"Doc{i+1}\" for i in range(len(corpus))]\n",
    ")\n",
    "\n",
    "print(\"‚öñÔ∏è Matriz TF-IDF:\\n\")\n",
    "print(df_tfidf.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis de palabras m√°s relevantes por documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada documento, mostramos las 5 palabras con mayor TF-IDF\n",
    "print(\"üîù Top 5 palabras m√°s relevantes por documento (TF-IDF):\\n\")\n",
    "\n",
    "for i, doc_name in enumerate(df_tfidf.index):\n",
    "    # Ordenamos las palabras por TF-IDF descendente\n",
    "    top_palabras = df_tfidf.loc[doc_name].sort_values(ascending=False).head(5)\n",
    "    \n",
    "    print(f\"üìÑ {doc_name}: {corpus[i][:60]}...\")\n",
    "    print(\"   Palabras clave:\")\n",
    "    for palabra, score in top_palabras.items():\n",
    "        if score > 0:\n",
    "            print(f\"      ‚Ä¢ {palabra:20} (score: {score:.3f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üìù EJERCICIO 5: Comparaci√≥n BoW vs TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Compara BoW y TF-IDF para la palabra \"inteligencia\"\n",
    "\n",
    "palabra_analizar = \"inteligencia\"\n",
    "\n",
    "if palabra_analizar in df_bow.columns:\n",
    "    print(f\"üîç An√°lisis de la palabra: '{palabra_analizar}'\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nüìä Bag of Words (frecuencias absolutas):\\n\")\n",
    "    for doc in df_bow.index:\n",
    "        valor_bow = df_bow.loc[doc, palabra_analizar]\n",
    "        print(f\"  {doc}: {valor_bow} apariciones\")\n",
    "    \n",
    "    print(\"\\nüìä TF-IDF (importancia ponderada):\\n\")\n",
    "    for doc in df_tfidf.index:\n",
    "        valor_tfidf = df_tfidf.loc[doc, palabra_analizar]\n",
    "        print(f\"  {doc}: {valor_tfidf:.4f} score\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\nüí° Observaci√≥n:\")\n",
    "    print(\"   - BoW cuenta frecuencias brutas\")\n",
    "    print(\"   - TF-IDF pondera por rareza: si aparece en pocos docs, mayor peso\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è La palabra '{palabra_analizar}' no est√° en el vocabulario\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 6: A√±ade un nuevo documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: A√±ade un documento nuevo y observa c√≥mo cambian los scores TF-IDF\n",
    "\n",
    "# Corpus original\n",
    "corpus_extendido = corpus.copy()\n",
    "\n",
    "# A√±ade tu documento aqu√≠:\n",
    "nuevo_documento = \"\"  # Ejemplo: \"Los agentes de IA pueden planificar y ejecutar tareas complejas\"\n",
    "\n",
    "if nuevo_documento:\n",
    "    corpus_extendido.append(nuevo_documento)\n",
    "    \n",
    "    # Recalculamos TF-IDF\n",
    "    tfidf_nuevo = TfidfVectorizer()\n",
    "    tfidf_matrix_nuevo = tfidf_nuevo.fit_transform(corpus_extendido)\n",
    "    \n",
    "    df_tfidf_nuevo = pd.DataFrame(\n",
    "        tfidf_matrix_nuevo.toarray(),\n",
    "        columns=tfidf_nuevo.get_feature_names_out(),\n",
    "        index=[f\"Doc{i+1}\" for i in range(len(corpus_extendido))]\n",
    "    )\n",
    "    \n",
    "    print(\"üìä TF-IDF con el nuevo documento:\\n\")\n",
    "    print(df_tfidf_nuevo.round(3))\n",
    "    \n",
    "    # Analizamos el nuevo documento\n",
    "    print(\"\\nüÜï Palabras m√°s relevantes del nuevo documento:\\n\")\n",
    "    top_nuevo = df_tfidf_nuevo.iloc[-1].sort_values(ascending=False).head(8)\n",
    "    for palabra, score in top_nuevo.items():\n",
    "        if score > 0:\n",
    "            print(f\"  ‚Ä¢ {palabra:20} {score:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è A√±ade un texto en la variable 'nuevo_documento'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 7: Visualizaci√≥n comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Visualiza la comparaci√≥n entre BoW y TF-IDF para un documento\n",
    "\n",
    "# Seleccionamos el primer documento\n",
    "doc_idx = 0\n",
    "doc_nombre = f\"Doc{doc_idx+1}\"\n",
    "\n",
    "# Obtenemos las top 10 palabras en ambas representaciones\n",
    "top_bow = df_bow.loc[doc_nombre].sort_values(ascending=False).head(10)\n",
    "top_tfidf = df_tfidf.loc[doc_nombre].sort_values(ascending=False).head(10)\n",
    "\n",
    "# Creamos subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Gr√°fico BoW\n",
    "axes[0].barh(top_bow.index, top_bow.values, color='coral', edgecolor='black')\n",
    "axes[0].set_xlabel('Frecuencia', fontsize=11)\n",
    "axes[0].set_title('Bag of Words', fontsize=13, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Gr√°fico TF-IDF\n",
    "axes[1].barh(top_tfidf.index, top_tfidf.values, color='steelblue', edgecolor='black')\n",
    "axes[1].set_xlabel('Score TF-IDF', fontsize=11)\n",
    "axes[1].set_title('TF-IDF', fontsize=13, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Comparaci√≥n: {doc_nombre}', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Visualizaci√≥n comparativa para: {corpus[doc_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Embeddings Modernos\n",
    "\n",
    "### Del espacio simb√≥lico al espacio sem√°ntico\n",
    "\n",
    "Las representaciones anteriores (BoW, TF-IDF) tienen una **limitaci√≥n fundamental**:\n",
    "- Tratan las palabras como s√≠mbolos independientes\n",
    "- No capturan relaciones sem√°nticas\n",
    "- \"rey\" y \"monarca\" son tan diferentes como \"rey\" y \"manzana\"\n",
    "\n",
    "---\n",
    "\n",
    "### ¬øQu√© son los embeddings?\n",
    "\n",
    "**Embeddings** = Representaciones vectoriales **densas** que capturan el **significado sem√°ntico**\n",
    "\n",
    "**Caracter√≠sticas**:\n",
    "- Vectores de dimensi√≥n fija (ej: 300, 768, 1024)\n",
    "- Palabras similares ‚Üí vectores cercanos en el espacio\n",
    "- Permiten aritm√©tica sem√°ntica: `Rey - Hombre + Mujer ‚âà Reina`\n",
    "\n",
    "---\n",
    "\n",
    "### Evoluci√≥n de los embeddings\n",
    "\n",
    "#### **1. Word2Vec (2013)**\n",
    "- **Idea**: \"Una palabra se entiende por las palabras que la rodean\"\n",
    "- **Arquitecturas**: CBOW (Continuous Bag of Words), Skip-gram\n",
    "- **Limitaci√≥n**: Un embedding fijo por palabra (no contextual)\n",
    "\n",
    "#### **2. GloVe (2014)**\n",
    "- Global Vectors for Word Representation\n",
    "- Basado en matriz de co-ocurrencias globales\n",
    "- Captura tanto estad√≠sticas locales como globales\n",
    "\n",
    "#### **3. Embeddings Contextualizados (2018+)**\n",
    "- **BERT, GPT, RoBERTa**: Embeddings que cambian seg√∫n el contexto\n",
    "- Ejemplo: \"banco\" (instituci√≥n financiera) vs \"banco\" (asiento)\n",
    "  - Antes: mismo vector para ambos\n",
    "  - Ahora: vectores diferentes seg√∫n contexto\n",
    "\n",
    "#### **4. Sentence Transformers (2019+)**\n",
    "- Embeddings para **frases completas**, no solo palabras\n",
    "- Optimizados para tareas de similitud sem√°ntica\n",
    "- Base de sistemas de b√∫squeda sem√°ntica y RAG\n",
    "\n",
    "---\n",
    "\n",
    "### Aplicaciones\n",
    "\n",
    "- **B√∫squeda sem√°ntica**: Encontrar documentos similares\n",
    "- **Sistemas de recomendaci√≥n**: Productos, contenidos\n",
    "- **Clustering**: Agrupar textos por tema\n",
    "- **Clasificaci√≥n**: Input para modelos de ML\n",
    "- **RAG**: Recuperaci√≥n de contexto relevante\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos sentence-transformers\n",
    "!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos un modelo de embeddings multiling√ºe optimizado para espa√±ol\n",
    "modelo_embeddings = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "print(\"‚úÖ Modelo de embeddings cargado\")\n",
    "print(f\"üìä Dimensi√≥n de los embeddings: {modelo_embeddings.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frases para generar embeddings\n",
    "frases = [\n",
    "    \"El perro corre por el parque\",\n",
    "    \"Un canino est√° corriendo en el jard√≠n\",\n",
    "    \"El gato duerme en el sof√°\",\n",
    "    \"Python es un lenguaje de programaci√≥n\",\n",
    "    \"Machine learning es una rama de la inteligencia artificial\",\n",
    "    \"La IA est√° transformando el mundo\",\n",
    "    \"Me gusta comer pizza\",\n",
    "    \"La pizza es mi comida favorita\"\n",
    "]\n",
    "\n",
    "print(\"üìù Frases de entrada:\\n\")\n",
    "for i, frase in enumerate(frases, 1):\n",
    "    print(f\"{i}. {frase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos embeddings\n",
    "embeddings = modelo_embeddings.encode(frases)\n",
    "\n",
    "print(f\"‚úÖ Embeddings generados\")\n",
    "print(f\"üìä Forma de la matriz: {embeddings.shape}\")\n",
    "print(f\"    {len(frases)} frases √ó {embeddings.shape[1]} dimensiones\")\n",
    "\n",
    "print(f\"\\nüîç Ejemplo - Embedding de la primera frase:\")\n",
    "print(f\"   '{frases[0]}'\")\n",
    "print(f\"   Primeros 10 valores: {embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C√°lculo de similitud sem√°ntica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la matriz de similitud del coseno\n",
    "matriz_similitud = cosine_similarity(embeddings)\n",
    "\n",
    "# Creamos un DataFrame para mejor visualizaci√≥n\n",
    "df_similitud = pd.DataFrame(\n",
    "    matriz_similitud,\n",
    "    index=[f\"F{i+1}\" for i in range(len(frases))],\n",
    "    columns=[f\"F{i+1}\" for i in range(len(frases))]\n",
    ")\n",
    "\n",
    "print(\"üìä Matriz de Similitud Sem√°ntica (0=diferentes, 1=id√©nticas):\\n\")\n",
    "print(df_similitud.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos con un mapa de calor\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(matriz_similitud, cmap='RdYlGn', interpolation='nearest', vmin=0, vmax=1)\n",
    "plt.colorbar(label='Similitud del Coseno', shrink=0.8)\n",
    "plt.title('Mapa de Calor - Similitud Sem√°ntica entre Frases', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xticks(range(len(frases)), [f\"F{i+1}\" for i in range(len(frases))])\n",
    "plt.yticks(range(len(frases)), [f\"F{i+1}\" for i in range(len(frases))])\n",
    "\n",
    "# A√±adimos valores en cada celda\n",
    "for i in range(len(frases)):\n",
    "    for j in range(len(frases)):\n",
    "        valor = matriz_similitud[i, j]\n",
    "        color = 'white' if valor > 0.7 else 'black'\n",
    "        plt.text(j, i, f'{valor:.2f}', ha='center', va='center', color=color, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìù Leyenda de frases:\")\n",
    "for i, frase in enumerate(frases, 1):\n",
    "    print(f\"F{i}: {frase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontramos los pares m√°s similares (excluyendo similitud consigo mismo)\n",
    "print(\"üîù Top 5 pares de frases m√°s similares:\\n\")\n",
    "\n",
    "# Creamos una lista de pares con su similitud\n",
    "pares_similitud = []\n",
    "for i in range(len(frases)):\n",
    "    for j in range(i+1, len(frases)):  # Solo la mitad superior de la matriz\n",
    "        pares_similitud.append((i, j, matriz_similitud[i, j]))\n",
    "\n",
    "# Ordenamos por similitud descendente\n",
    "pares_similitud.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Mostramos los top 5\n",
    "for idx, (i, j, sim) in enumerate(pares_similitud[:5], 1):\n",
    "    print(f\"{idx}. Similitud: {sim:.4f}\")\n",
    "    print(f\"   ‚Ä¢ {frases[i]}\")\n",
    "    print(f\"   ‚Ä¢ {frases[j]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducci√≥n dimensional y visualizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducimos de 384 dimensiones a 2 usando PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "print(f\"‚úÖ Reducci√≥n dimensional completada\")\n",
    "print(f\"üìä Varianza explicada: {sum(pca.explained_variance_ratio_)*100:.2f}%\")\n",
    "\n",
    "# Visualizamos en 2D\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=300, c='skyblue', edgecolors='navy', linewidths=2)\n",
    "\n",
    "# A√±adimos etiquetas\n",
    "for i, frase in enumerate(frases):\n",
    "    plt.annotate(\n",
    "        f\"F{i+1}\",\n",
    "        (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "        fontsize=12,\n",
    "        ha='center',\n",
    "        va='center',\n",
    "        fontweight='bold'\n",
    "    )\n",
    "\n",
    "plt.xlabel('Componente Principal 1', fontsize=12)\n",
    "plt.ylabel('Componente Principal 2', fontsize=12)\n",
    "plt.title('Visualizaci√≥n 2D de Embeddings Sem√°nticos', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìù Leyenda:\")\n",
    "for i, frase in enumerate(frases, 1):\n",
    "    print(f\"F{i}: {frase}\")\n",
    "\n",
    "print(\"\\nüí° Nota: Frases sem√°nticamente similares deber√≠an estar m√°s cercanas en el gr√°fico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üìù EJERCICIO 8: A√±ade nuevas frases y analiza similitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: A√±ade 3 frases nuevas y observa su similitud con las existentes\n",
    "\n",
    "# A√±ade tus frases aqu√≠:\n",
    "nuevas_frases = [\n",
    "    # Ejemplo: \"Los algoritmos de IA aprenden de los datos\",\n",
    "    \n",
    "]\n",
    "\n",
    "if nuevas_frases:\n",
    "    # Generamos embeddings de las nuevas frases\n",
    "    nuevos_embeddings = modelo_embeddings.encode(nuevas_frases)\n",
    "    \n",
    "    print(\"üÜï An√°lisis de similitud para tus frases:\\n\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, nueva_frase in enumerate(nuevas_frases):\n",
    "        # Calculamos similitud con todas las frases originales\n",
    "        similitudes = cosine_similarity([nuevos_embeddings[i]], embeddings)[0]\n",
    "        \n",
    "        # Encontramos las 3 m√°s similares\n",
    "        indices_top = np.argsort(similitudes)[::-1][:3]\n",
    "        \n",
    "        print(f\"\\nüîç Nueva frase {i+1}: '{nueva_frase}'\")\n",
    "        print(\"\\n   Top 3 frases m√°s similares:\")\n",
    "        for rank, idx in enumerate(indices_top, 1):\n",
    "            print(f\"   {rank}. [{similitudes[idx]:.4f}] {frases[idx]}\")\n",
    "        print(\"-\"*80)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è A√±ade al menos una frase en la lista 'nuevas_frases'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 9: B√∫squeda sem√°ntica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Crea una funci√≥n de b√∫squeda sem√°ntica\n",
    "\n",
    "def buscar_frase_similar(query, frases_bd, embeddings_bd, top_k=3):\n",
    "    \"\"\"\n",
    "    Encuentra las frases m√°s similares a una query.\n",
    "    \n",
    "    Args:\n",
    "        query: Texto de b√∫squeda\n",
    "        frases_bd: Lista de frases en la base de datos\n",
    "        embeddings_bd: Embeddings de las frases\n",
    "        top_k: N√∫mero de resultados a retornar\n",
    "    \n",
    "    Returns:\n",
    "        Lista de tuplas (frase, similitud)\n",
    "    \"\"\"\n",
    "    # Generamos embedding de la query\n",
    "    query_embedding = modelo_embeddings.encode([query])\n",
    "    \n",
    "    # Calculamos similitudes\n",
    "    similitudes = cosine_similarity(query_embedding, embeddings_bd)[0]\n",
    "    \n",
    "    # Ordenamos y obtenemos top_k\n",
    "    indices_top = np.argsort(similitudes)[::-1][:top_k]\n",
    "    \n",
    "    resultados = [(frases_bd[idx], similitudes[idx]) for idx in indices_top]\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Probamos la funci√≥n\n",
    "consulta = \"animales dom√©sticos\"  # Cambia esta consulta\n",
    "\n",
    "print(f\"üîé B√∫squeda: '{consulta}'\\n\")\n",
    "print(\"Resultados m√°s relevantes:\\n\")\n",
    "\n",
    "resultados = buscar_frase_similar(consulta, frases, embeddings, top_k=5)\n",
    "\n",
    "for i, (frase, sim) in enumerate(resultados, 1):\n",
    "    print(f\"{i}. [{sim:.4f}] {frase}\")\n",
    "\n",
    "print(\"\\nüí° Prueba con otras consultas cambiando la variable 'consulta'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 10: Clustering de frases por tema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Agrupa las frases por tema usando K-means\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Definimos el n√∫mero de clusters (temas)\n",
    "n_clusters = 3  # Puedes cambiar este n√∫mero\n",
    "\n",
    "# Aplicamos K-means\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "print(f\"üìä Agrupaci√≥n de frases en {n_clusters} clusters (temas):\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for cluster_id in range(n_clusters):\n",
    "    print(f\"\\nüè∑Ô∏è Cluster {cluster_id + 1}:\")\n",
    "    indices = [i for i, c in enumerate(clusters) if c == cluster_id]\n",
    "    for idx in indices:\n",
    "        print(f\"   ‚Ä¢ {frases[idx]}\")\n",
    "\n",
    "# Visualizaci√≥n con colores por cluster\n",
    "plt.figure(figsize=(12, 8))\n",
    "colores = plt.cm.Set3(clusters)\n",
    "\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=300, c=colores, edgecolors='black', linewidths=2)\n",
    "\n",
    "for i, frase in enumerate(frases):\n",
    "    plt.annotate(\n",
    "        f\"F{i+1}\\n(C{clusters[i]+1})\",\n",
    "        (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "        fontsize=9,\n",
    "        ha='center',\n",
    "        va='center'\n",
    "    )\n",
    "\n",
    "plt.xlabel('Componente Principal 1', fontsize=12)\n",
    "plt.ylabel('Componente Principal 2', fontsize=12)\n",
    "plt.title(f'Clustering de Frases por Similitud Sem√°ntica ({n_clusters} clusters)', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Clasificaci√≥n con Modelos Tipo BERT (Encoder)\n",
    "\n",
    "### Arquitecturas Transformer: Encoder vs Decoder\n",
    "\n",
    "Los transformers se pueden clasificar en tres categor√≠as seg√∫n su arquitectura:\n",
    "\n",
    "---\n",
    "\n",
    "### **üîç Encoder-only (BERT, RoBERTa, DistilBERT)**\n",
    "\n",
    "**Funci√≥n**: **Comprensi√≥n** y **representaci√≥n** de texto\n",
    "\n",
    "**Caracter√≠sticas**:\n",
    "- Atenci√≥n **bidireccional**: Lee el texto completo en ambas direcciones\n",
    "- Genera representaciones contextualizadas de cada token\n",
    "- No dise√±ado para generar texto nuevo\n",
    "\n",
    "**Usos principales**:\n",
    "- ‚úÖ Clasificaci√≥n de texto (sentimientos, spam, categor√≠as)\n",
    "- ‚úÖ Named Entity Recognition (NER)\n",
    "- ‚úÖ Question Answering\n",
    "- ‚úÖ Extracci√≥n de informaci√≥n\n",
    "- ‚úÖ An√°lisis de similitud\n",
    "\n",
    "**Ejemplo**: BERT\n",
    "- Pre-entrenado con Masked Language Modeling (MLM)\n",
    "- Predice palabras ocultas en un contexto bidireccional\n",
    "\n",
    "---\n",
    "\n",
    "### **‚úçÔ∏è Decoder-only (GPT, LLaMA, Claude)**\n",
    "\n",
    "**Funci√≥n**: **Generaci√≥n** de texto\n",
    "\n",
    "**Caracter√≠sticas**:\n",
    "- Atenci√≥n **unidireccional** (solo hacia la izquierda)\n",
    "- Predice el siguiente token bas√°ndose en los anteriores\n",
    "- Autore Gresivo: genera palabra por palabra\n",
    "\n",
    "**Usos principales**:\n",
    "- ‚úÖ Generaci√≥n de texto (historias, art√≠culos)\n",
    "- ‚úÖ Chatbots y asistentes conversacionales\n",
    "- ‚úÖ Completado de c√≥digo\n",
    "- ‚úÖ Traducci√≥n (con prompt adecuado)\n",
    "- ‚úÖ Res√∫menes\n",
    "\n",
    "**Ejemplo**: GPT-3/4\n",
    "- Pre-entrenado con Causal Language Modeling\n",
    "- Predice la siguiente palabra dadas las anteriores\n",
    "\n",
    "---\n",
    "\n",
    "### **üîÑ Encoder-Decoder (T5, BART, mBART)**\n",
    "\n",
    "**Funci√≥n**: **Transformaci√≥n** de texto (input ‚Üí output)\n",
    "\n",
    "**Caracter√≠sticas**:\n",
    "- Encoder: comprende el input\n",
    "- Decoder: genera el output\n",
    "- Ideal cuando input y output son diferentes\n",
    "\n",
    "**Usos principales**:\n",
    "- ‚úÖ Traducci√≥n autom√°tica\n",
    "- ‚úÖ Res√∫menes (texto largo ‚Üí resumen corto)\n",
    "- ‚úÖ Par√°frasis\n",
    "- ‚úÖ Correcci√≥n gramatical\n",
    "\n",
    "---\n",
    "\n",
    "### Tabla Comparativa\n",
    "\n",
    "| Arquitectura | Atenci√≥n | Tarea Principal | Ejemplos | Mejor para |\n",
    "|--------------|----------|-----------------|----------|------------|\n",
    "| Encoder | Bidireccional | Comprensi√≥n | BERT, RoBERTa | Clasificaci√≥n, NER |\n",
    "| Decoder | Unidireccional | Generaci√≥n | GPT, LLaMA | Chatbots, escritura |\n",
    "| Encoder-Decoder | Ambas | Transformaci√≥n | T5, BART | Traducci√≥n, resumen |\n",
    "\n",
    "---\n",
    "\n",
    "### An√°lisis de Sentimientos con BERT\n",
    "\n",
    "Vamos a usar un modelo BERT fine-tuneado para clasificar sentimientos en espa√±ol.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos transformers\n",
    "!pip install -q transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Cargamos un modelo BERT multiling√ºe fine-tuneado para an√°lisis de sentimientos\n",
    "# Este modelo clasifica en 5 estrellas (1=muy negativo, 5=muy positivo)\n",
    "clasificador_sentimientos = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    device=-1  # CPU (-1), cambiar a 0 para GPU\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Modelo de clasificaci√≥n de sentimientos cargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frases de ejemplo con diferentes sentimientos\n",
    "frases_sentimientos = [\n",
    "    \"Esta pel√≠cula es absolutamente incre√≠ble, la mejor que he visto en a√±os\",\n",
    "    \"Me encant√≥ el servicio, muy profesional y r√°pido\",\n",
    "    \"El producto es aceptable, cumple con lo esperado\",\n",
    "    \"No me gust√≥ para nada, muy decepcionante\",\n",
    "    \"P√©sima experiencia, nunca volver√© a comprar aqu√≠\",\n",
    "    \"El hotel est√° bien ubicado pero las habitaciones son peque√±as\",\n",
    "    \"Excelente calidad-precio, totalmente recomendable\",\n",
    "    \"El libro es interesante aunque un poco largo\",\n",
    "    \"Horrible, una p√©rdida total de tiempo y dinero\",\n",
    "    \"Fant√°stico, super√≥ todas mis expectativas\"\n",
    "]\n",
    "\n",
    "print(\"üìù Frases a clasificar:\\n\")\n",
    "for i, frase in enumerate(frases_sentimientos, 1):\n",
    "    print(f\"{i:2}. {frase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificamos todas las frases\n",
    "resultados = clasificador_sentimientos(frases_sentimientos)\n",
    "\n",
    "print(\"üéØ Resultados de la Clasificaci√≥n:\\n\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "for i, (frase, resultado) in enumerate(zip(frases_sentimientos, resultados), 1):\n",
    "    label = resultado['label']\n",
    "    score = resultado['score']\n",
    "    estrellas_num = int(label.split()[0])\n",
    "    \n",
    "    # Categor√≠a sem√°ntica\n",
    "    if estrellas_num <= 2:\n",
    "        categoria = \"üòû Negativo\"\n",
    "        color = \"üî¥\"\n",
    "    elif estrellas_num == 3:\n",
    "        categoria = \"üòê Neutral\"\n",
    "        color = \"üü°\"\n",
    "    else:\n",
    "        categoria = \"üòä Positivo\"\n",
    "        color = \"üü¢\"\n",
    "    \n",
    "    print(f\"\\n{i:2}. {frase[:70]}...\" if len(frase) > 70 else f\"\\n{i:2}. {frase}\")\n",
    "    print(f\"    {color} {categoria:15} | {label:8} | Confianza: {score*100:5.2f}% | {'‚≠ê' * estrellas_num}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame con los resultados\n",
    "datos_clasificacion = []\n",
    "\n",
    "for frase, resultado in zip(frases_sentimientos, resultados):\n",
    "    estrellas = int(resultado['label'].split()[0])\n",
    "    \n",
    "    if estrellas <= 2:\n",
    "        sentimiento = \"Negativo\"\n",
    "    elif estrellas == 3:\n",
    "        sentimiento = \"Neutral\"\n",
    "    else:\n",
    "        sentimiento = \"Positivo\"\n",
    "    \n",
    "    datos_clasificacion.append({\n",
    "        'Frase': frase[:60] + '...' if len(frase) > 60 else frase,\n",
    "        'Sentimiento': sentimiento,\n",
    "        'Estrellas': estrellas,\n",
    "        'Confianza': f\"{resultado['score']*100:.1f}%\"\n",
    "    })\n",
    "\n",
    "df_clasificacion = pd.DataFrame(datos_clasificacion)\n",
    "\n",
    "print(\"üìä Tabla de Clasificaci√≥n:\\n\")\n",
    "print(df_clasificacion.to_string(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas de clasificaci√≥n\n",
    "conteo_sentimientos = df_clasificacion['Sentimiento'].value_counts()\n",
    "\n",
    "print(\"\\nüìà Distribuci√≥n de Sentimientos:\\n\")\n",
    "print(conteo_sentimientos)\n",
    "\n",
    "# Visualizaci√≥n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gr√°fico de barras\n",
    "colores_sentimientos = {'Positivo': 'green', 'Neutral': 'gray', 'Negativo': 'red'}\n",
    "colores_plot = [colores_sentimientos[sent] for sent in conteo_sentimientos.index]\n",
    "\n",
    "axes[0].bar(conteo_sentimientos.index, conteo_sentimientos.values, color=colores_plot, edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_xlabel('Sentimiento', fontsize=11)\n",
    "axes[0].set_ylabel('Cantidad', fontsize=11)\n",
    "axes[0].set_title('Distribuci√≥n de Sentimientos', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Gr√°fico de pastel\n",
    "axes[1].pie(\n",
    "    conteo_sentimientos.values,\n",
    "    labels=conteo_sentimientos.index,\n",
    "    autopct='%1.1f%%',\n",
    "    colors=colores_plot,\n",
    "    startangle=90,\n",
    "    textprops={'fontsize': 11, 'fontweight': 'bold'}\n",
    ")\n",
    "axes[1].set_title('Proporci√≥n de Sentimientos', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üìù EJERCICIO 11: Clasifica tus propias frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: A√±ade 10 frases propias y clasif√≠calas\n",
    "\n",
    "mis_frases = [\n",
    "    # A√±ade aqu√≠ tus 10 frases (opiniones, rese√±as, comentarios)\n",
    "    # Ejemplo: \"Me pareci√≥ interesante pero le falta profundidad\",\n",
    "    \n",
    "]\n",
    "\n",
    "if mis_frases and len(mis_frases) >= 5:\n",
    "    # Clasificamos\n",
    "    mis_resultados = clasificador_sentimientos(mis_frases)\n",
    "    \n",
    "    print(\"üéØ Clasificaci√≥n de tus frases:\\n\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    for i, (frase, res) in enumerate(zip(mis_frases, mis_resultados), 1):\n",
    "        estrellas = int(res['label'].split()[0])\n",
    "        \n",
    "        if estrellas <= 2:\n",
    "            emoji = \"üòû\"\n",
    "            sent = \"Negativo\"\n",
    "        elif estrellas == 3:\n",
    "            emoji = \"üòê\"\n",
    "            sent = \"Neutral\"\n",
    "        else:\n",
    "            emoji = \"üòä\"\n",
    "            sent = \"Positivo\"\n",
    "        \n",
    "        print(f\"\\n{i}. {frase}\")\n",
    "        print(f\"   {emoji} {sent} | {res['label']} | {res['score']*100:.1f}% confianza\")\n",
    "    \n",
    "    # Estad√≠sticas\n",
    "    categorias = [\"Negativo\" if int(r['label'].split()[0]) <= 2 else \"Neutral\" if int(r['label'].split()[0]) == 3 else \"Positivo\" for r in mis_resultados]\n",
    "    conteo = pd.Series(categorias).value_counts()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"\\nüìä Resumen:\")\n",
    "    print(conteo)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è A√±ade al menos 5 frases en la lista 'mis_frases'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 12: Compara diferentes modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Prueba con otro modelo y compara resultados\n",
    "\n",
    "# Cargamos un segundo modelo (m√°s simple, basado en distilbert)\n",
    "clasificador_2 = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Segundo modelo cargado (DistilBERT-SST2)\\n\")\n",
    "\n",
    "# Frases de prueba en ingl√©s (este modelo solo funciona en ingl√©s)\n",
    "frases_prueba = [\n",
    "    \"This movie is absolutely amazing, I loved it!\",\n",
    "    \"Terrible experience, worst service ever\",\n",
    "    \"It was okay, nothing special\"\n",
    "]\n",
    "\n",
    "print(\"üîç Comparaci√≥n de modelos:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for frase in frases_prueba:\n",
    "    resultado = clasificador_2([frase])[0]\n",
    "    \n",
    "    print(f\"\\nFrase: {frase}\")\n",
    "    print(f\"Modelo 2: {resultado['label']} (confianza: {resultado['score']*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nüí° Observaci√≥n:\")\n",
    "print(\"   - Diferentes modelos pueden clasificar de forma distinta\")\n",
    "print(\"   - Importante elegir el modelo adecuado para tu idioma y tarea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Generaci√≥n con Modelos Tipo GPT (Decoder)\n",
    "\n",
    "### ¬øC√≥mo funcionan los modelos generativos?\n",
    "\n",
    "Los modelos decoder como GPT est√°n dise√±ados para **generar texto** prediciendo el siguiente token de forma autoregresiva.\n",
    "\n",
    "---\n",
    "\n",
    "### Proceso de Generaci√≥n\n",
    "\n",
    "1. **Input**: Prompt inicial ‚Üí `\"El gato est√°\"`\n",
    "2. **Predicci√≥n**: Modelo predice siguiente palabra ‚Üí `\"sentado\"` (probabilidad 60%), `\"durmiendo\"` (35%), ...\n",
    "3. **Selecci√≥n**: Se elige una palabra seg√∫n estrategia (temperature, top-k, top-p)\n",
    "4. **Iteraci√≥n**: Nueva secuencia ‚Üí `\"El gato est√° sentado\"` ‚Üí predice siguiente ‚Üí ...\n",
    "5. **Fin**: Hasta alcanzar max_length o token especial de fin\n",
    "\n",
    "---\n",
    "\n",
    "### Par√°metros de Generaci√≥n\n",
    "\n",
    "#### **Temperature (œÑ)**\n",
    "Controla la \"creatividad\" del modelo\n",
    "\n",
    "```\n",
    "P'(token) = P(token)^(1/œÑ)\n",
    "```\n",
    "\n",
    "- **œÑ = 0.1 - 0.5**: Conservador, predecible, determinista\n",
    "  - Uso: Tareas que requieren precisi√≥n (c√≥digo, datos)\n",
    "- **œÑ = 0.7 - 1.0**: Balanceado\n",
    "  - Uso: Escritura general, chatbots\n",
    "- **œÑ = 1.2 - 2.0**: Creativo, aleatorio, diverso\n",
    "  - Uso: Escritura creativa, brainstorming\n",
    "\n",
    "#### **Top-k Sampling**\n",
    "Limita las opciones a las K palabras m√°s probables\n",
    "\n",
    "- **k=1**: Greedy decoding (siempre la m√°s probable)\n",
    "- **k=10-50**: Balanceado\n",
    "- **k=100+**: M√°s diversidad\n",
    "\n",
    "#### **Top-p (Nucleus) Sampling**\n",
    "Considera palabras hasta alcanzar probabilidad acumulada P\n",
    "\n",
    "- **p=0.5**: Muy conservador\n",
    "- **p=0.9**: Balanceado (recomendado)\n",
    "- **p=0.95-1.0**: M√°s diversidad\n",
    "\n",
    "#### **Max Length / Max New Tokens**\n",
    "- N√∫mero m√°ximo de tokens a generar\n",
    "\n",
    "---\n",
    "\n",
    "### Estrategias de Decodificaci√≥n\n",
    "\n",
    "| Estrategia | Descripci√≥n | Uso |\n",
    "|------------|-------------|-----|\n",
    "| Greedy | Siempre token m√°s probable | Muy determinista, puede ser repetitivo |\n",
    "| Beam Search | Mantiene N mejores secuencias | Traducciones, res√∫menes |\n",
    "| Top-k Sampling | Muestrea entre top-K tokens | Balance creatividad/coherencia |\n",
    "| Top-p Sampling | Probabilidad acumulada | Recomendado para texto general |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos un modelo generativo peque√±o (DistilGPT-2)\n",
    "# Nota: Est√° entrenado en ingl√©s, para espa√±ol hay alternativas como GPT-2-small-spanish\n",
    "\n",
    "generador = pipeline(\n",
    "    'text-generation',\n",
    "    model='distilgpt2',\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Modelo generativo cargado (DistilGPT-2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generaci√≥n b√°sica con configuraci√≥n por defecto\n",
    "prompt = \"Artificial intelligence is transforming\"\n",
    "\n",
    "resultado = generador(\n",
    "    prompt,\n",
    "    max_length=50,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"üìù Generaci√≥n B√°sica:\\n\")\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"\\nTexto generado:\\n{resultado[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üìù EJERCICIO 13: Experimenta con Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Genera textos con diferentes valores de temperature\n",
    "\n",
    "prompt = \"The future of technology will\"\n",
    "\n",
    "temperaturas = [0.2, 0.7, 1.2]\n",
    "\n",
    "print(\"üå°Ô∏è Experimento: Efecto de la Temperature\\n\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "for temp in temperaturas:\n",
    "    print(f\"\\nüîπ Temperature = {temp}\")\n",
    "    print(\"-\"*90)\n",
    "    \n",
    "    resultados = generador(\n",
    "        prompt,\n",
    "        max_length=50,\n",
    "        temperature=temp,\n",
    "        num_return_sequences=2,  # Generamos 2 versiones\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    for i, res in enumerate(resultados, 1):\n",
    "        print(f\"\\nVersi√≥n {i}:\")\n",
    "        print(res['generated_text'])\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*90)\n",
    "\n",
    "print(\"\\nüí° An√°lisis:\")\n",
    "print(\"   Temperature baja (0.2)  ‚Üí M√°s predecible y coherente\")\n",
    "print(\"   Temperature media (0.7) ‚Üí Balance entre creatividad y coherencia\")\n",
    "print(\"   Temperature alta (1.2)  ‚Üí M√°s creativo pero potencialmente incoherente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 14: Top-k y Top-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Compara diferentes configuraciones de top-k y top-p\n",
    "\n",
    "prompt = \"In a distant future, humanity discovered\"\n",
    "\n",
    "configuraciones = [\n",
    "    {\"nombre\": \"Conservador\", \"top_k\": 10, \"top_p\": 0.5},\n",
    "    {\"nombre\": \"Balanceado\", \"top_k\": 50, \"top_p\": 0.9},\n",
    "    {\"nombre\": \"Creativo\", \"top_k\": 100, \"top_p\": 0.95}\n",
    "]\n",
    "\n",
    "print(\"üéØ Experimento: Top-k y Top-p Sampling\\n\")\n",
    "print(\"=\"*90)\n",
    "print(f\"\\nPrompt: '{prompt}'\\n\")\n",
    "\n",
    "for config in configuraciones:\n",
    "    print(f\"\\nüîπ {config['nombre']} (top_k={config['top_k']}, top_p={config['top_p']})\")\n",
    "    print(\"-\"*90)\n",
    "    \n",
    "    resultado = generador(\n",
    "        prompt,\n",
    "        max_length=60,\n",
    "        temperature=0.8,\n",
    "        top_k=config['top_k'],\n",
    "        top_p=config['top_p'],\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{resultado[0]['generated_text']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"\\nüí° Observaciones:\")\n",
    "print(\"   - top_k bajo: Reduce opciones a las m√°s probables\")\n",
    "print(\"   - top_p bajo: Corta la 'cola' de probabilidades antes\")\n",
    "print(\"   - Combinaci√≥n de ambos: Control fino sobre creatividad vs coherencia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 15: Crea tu propio prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Define tu propio prompt y genera m√∫ltiples versiones\n",
    "\n",
    "# Define tu prompt aqu√≠:\n",
    "mi_prompt = \"\"  # Ejemplo: \"The most important scientific discovery was\"\n",
    "\n",
    "if mi_prompt:\n",
    "    print(f\"üìù Tu prompt: '{mi_prompt}'\\n\")\n",
    "    print(\"=\"*90)\n",
    "    print(\"\\nüé≤ Generando 5 versiones diferentes...\\n\")\n",
    "    \n",
    "    resultados = generador(\n",
    "        mi_prompt,\n",
    "        max_length=70,\n",
    "        temperature=0.9,\n",
    "        top_k=50,\n",
    "        top_p=0.92,\n",
    "        num_return_sequences=5,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    for i, res in enumerate(resultados, 1):\n",
    "        print(f\"\\nüîπ Versi√≥n {i}:\")\n",
    "        print(\"-\"*90)\n",
    "        print(res['generated_text'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Define un prompt en la variable 'mi_prompt'\")\n",
    "    print(\"üí° Consejos:\")\n",
    "    print(\"   - Empieza con contexto claro\")\n",
    "    print(\"   - Deja la frase incompleta para que el modelo contin√∫e\")\n",
    "    print(\"   - Experimenta con diferentes temas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 16: Generaci√≥n con restricciones de longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Observa c√≥mo max_length afecta la generaci√≥n\n",
    "\n",
    "prompt = \"The three most important things in life are\"\n",
    "\n",
    "longitudes = [30, 60, 100]\n",
    "\n",
    "print(\"üìè Experimento: Efecto de max_length\\n\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "for max_len in longitudes:\n",
    "    print(f\"\\nüîπ Max length = {max_len} tokens\")\n",
    "    print(\"-\"*90)\n",
    "    \n",
    "    resultado = generador(\n",
    "        prompt,\n",
    "        max_length=max_len,\n",
    "        temperature=0.7,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    texto = resultado[0]['generated_text']\n",
    "    print(f\"\\n{texto}\")\n",
    "    print(f\"\\n[Longitud real: {len(texto.split())} palabras]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Prompt Engineering B√°sico\n",
    "\n",
    "### ¬øQu√© es Prompt Engineering?\n",
    "\n",
    "**Prompt Engineering** es el arte y ciencia de dise√±ar **instrucciones efectivas** para que los modelos de lenguaje generen las respuestas deseadas.\n",
    "\n",
    "---\n",
    "\n",
    "### Principios Fundamentales\n",
    "\n",
    "#### **1. Contexto Claro**\n",
    "Proporciona informaci√≥n de fondo necesaria\n",
    "\n",
    "‚ùå Malo: \"Explica\"\n",
    "‚úÖ Bueno: \"Explica c√≥mo funcionan las redes neuronales en el contexto de visi√≥n por computador\"\n",
    "\n",
    "#### **2. Rol/Persona**\n",
    "Define qui√©n debe \"ser\" el modelo\n",
    "\n",
    "```\n",
    "\"Eres un profesor de f√≠sica explicando a estudiantes de secundaria...\"\n",
    "\"Act√∫a como un experto en ciberseguridad...\"\n",
    "```\n",
    "\n",
    "#### **3. Formato de Salida**\n",
    "Especifica estructura deseada\n",
    "\n",
    "```\n",
    "\"Responde en forma de lista numerada\"\n",
    "\"Estructura tu respuesta en: 1) Introducci√≥n, 2) Desarrollo, 3) Conclusi√≥n\"\n",
    "\"Genera una tabla con columnas: Nombre, Ventaja, Desventaja\"\n",
    "```\n",
    "\n",
    "#### **4. Ejemplos (Few-shot Learning)**\n",
    "Muestra el tipo de respuesta esperada\n",
    "\n",
    "```\n",
    "\"Clasifica el sentimiento:\n",
    "\n",
    "Texto: 'Me encant√≥ la pel√≠cula'\n",
    "Sentimiento: Positivo\n",
    "\n",
    "Texto: 'Fue aburrida'\n",
    "Sentimiento: Negativo\n",
    "\n",
    "Texto: 'El servicio fue excelente'\n",
    "Sentimiento:\"\n",
    "```\n",
    "\n",
    "#### **5. Restricciones**\n",
    "L√≠mites de longitud, estilo, contenido\n",
    "\n",
    "```\n",
    "\"En m√°ximo 3 oraciones...\"\n",
    "\"Usando lenguaje t√©cnico apropiado para ingenieros...\"\n",
    "\"Sin usar jerga t√©cnica, para audiencia general...\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### T√©cnicas Avanzadas\n",
    "\n",
    "#### **Zero-shot**\n",
    "Sin ejemplos, solo instrucciones\n",
    "```\n",
    "\"Traduce al franc√©s: ...\"\n",
    "```\n",
    "\n",
    "#### **One-shot**\n",
    "Un ejemplo\n",
    "```\n",
    "\"Escribe en estilo formal:\n",
    "Informal: '¬øQu√© onda?'\n",
    "Formal: '¬øC√≥mo est√° usted?'\n",
    "\n",
    "Informal: '¬øTodo bien?'\n",
    "Formal:\"\n",
    "```\n",
    "\n",
    "#### **Few-shot**\n",
    "M√∫ltiples ejemplos (2-5)\n",
    "\n",
    "#### **Chain-of-Thought (CoT)**\n",
    "Pide razonamiento paso a paso\n",
    "```\n",
    "\"Resuelve paso a paso:\n",
    "Pregunta: Si 5 manzanas cuestan $10, ¬øcu√°nto cuestan 8 manzanas?\n",
    "\n",
    "Paso 1:\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Errores Comunes\n",
    "\n",
    "‚ùå **Vagos**: \"H√°blame de IA\"\n",
    "‚ùå **Ambiguos**: \"Escribe algo sobre esto\"\n",
    "‚ùå **Sin estructura**: Texto largo sin separaciones\n",
    "‚ùå **Contradictorios**: \"S√© breve pero detallado\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n auxiliar para generar respuestas\n",
    "def generar_respuesta(prompt, max_len=100, temp=0.7):\n",
    "    \"\"\"Genera una respuesta dado un prompt\"\"\"\n",
    "    resultado = generador(\n",
    "        prompt,\n",
    "        max_length=max_len,\n",
    "        temperature=temp,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True,\n",
    "        pad_token_id=50256  # Para evitar warnings\n",
    "    )\n",
    "    return resultado[0]['generated_text']\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de generaci√≥n definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaci√≥n: Prompts Malos vs Buenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 1: Prompt vago vs espec√≠fico\n",
    "print(\"üìã Ejemplo 1: Especificidad\\n\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Prompt MALO\n",
    "prompt_malo = \"Write about AI\"\n",
    "print(f\"\\n‚ùå PROMPT MALO (vago):\")\n",
    "print(f\"   '{prompt_malo}'\\n\")\n",
    "respuesta_mala = generar_respuesta(prompt_malo, max_len=60)\n",
    "print(f\"Respuesta:\\n{respuesta_mala}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*90 + \"\\n\")\n",
    "\n",
    "# Prompt BUENO\n",
    "prompt_bueno = \"\"\"Write a brief explanation of artificial intelligence for high school students.\n",
    "Include: 1) Definition, 2) One real-world example, 3) One benefit.\n",
    "Keep it under 100 words.\"\"\"\n",
    "\n",
    "print(f\"‚úÖ PROMPT BUENO (espec√≠fico y estructurado):\")\n",
    "print(f\"   {prompt_bueno}\\n\")\n",
    "respuesta_buena = generar_respuesta(prompt_bueno, max_len=120)\n",
    "print(f\"Respuesta:\\n{respuesta_buena}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 2: Sin contexto vs con contexto\n",
    "print(\"üìã Ejemplo 2: Importancia del Contexto\\n\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Sin contexto\n",
    "prompt_sin_contexto = \"What is Python?\"\n",
    "print(f\"\\n‚ùå SIN CONTEXTO:\")\n",
    "print(f\"   '{prompt_sin_contexto}'\\n\")\n",
    "resp1 = generar_respuesta(prompt_sin_contexto, max_len=50)\n",
    "print(f\"Respuesta:\\n{resp1}\")\n",
    "print(\"\\n(Podr√≠a referirse al animal o al lenguaje de programaci√≥n)\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*90 + \"\\n\")\n",
    "\n",
    "# Con contexto\n",
    "prompt_con_contexto = \"\"\"In the context of programming languages, explain what Python is \n",
    "and mention two key features that make it popular.\"\"\"\n",
    "\n",
    "print(f\"‚úÖ CON CONTEXTO CLARO:\")\n",
    "print(f\"   {prompt_con_contexto}\\n\")\n",
    "resp2 = generar_respuesta(prompt_con_contexto, max_len=80)\n",
    "print(f\"Respuesta:\\n{resp2}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üìù EJERCICIO 17: Mejora estos prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Transforma estos prompts mediocres en prompts efectivos\n",
    "\n",
    "prompts_mediocres = [\n",
    "    \"Tell me about climate change\",\n",
    "    \"Explain machine learning\",\n",
    "    \"What is a healthy diet\"\n",
    "]\n",
    "\n",
    "# Escribe aqu√≠ las versiones mejoradas:\n",
    "prompts_mejorados = [\n",
    "    # Mejora del primer prompt (ejemplo completado):\n",
    "    \"\"\"Explain climate change for a general audience.\n",
    "Structure: 1) What it is, 2) Main causes, 3) One concrete impact.\n",
    "Use simple language, maximum 80 words.\"\"\",\n",
    "    \n",
    "    # Mejora del segundo prompt (completa t√∫):\n",
    "    \"\",\n",
    "    \n",
    "    # Mejora del tercer prompt (completa t√∫):\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "# Comparamos los resultados\n",
    "if all(prompts_mejorados):  # Si todos est√°n completos\n",
    "    for i, (malo, bueno) in enumerate(zip(prompts_mediocres, prompts_mejorados), 1):\n",
    "        print(f\"\\n{'='*90}\")\n",
    "        print(f\"üìå CASO {i}\")\n",
    "        print(f\"{'='*90}\")\n",
    "        \n",
    "        print(f\"\\n‚ùå Prompt original (mediocre):\")\n",
    "        print(f\"   {malo}\\n\")\n",
    "        resp_mala = generar_respuesta(malo, max_len=60)\n",
    "        print(f\"Respuesta:\\n{resp_mala}\")\n",
    "        \n",
    "        print(f\"\\n{'-'*90}\\n\")\n",
    "        \n",
    "        print(f\"‚úÖ Prompt mejorado:\")\n",
    "        print(f\"   {bueno}\\n\")\n",
    "        resp_buena = generar_respuesta(bueno, max_len=100)\n",
    "        print(f\"Respuesta:\\n{resp_buena}\")\n",
    "        \n",
    "        print(f\"\\n{'='*90}\\n\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Completa los 3 prompts mejorados en la lista 'prompts_mejorados'\")\n",
    "    print(\"\\nüí° Consejos para mejorarlos:\")\n",
    "    print(\"   1. A√±ade contexto (audiencia, prop√≥sito)\")\n",
    "    print(\"   2. Especifica estructura de la respuesta\")\n",
    "    print(\"   3. Define restricciones (longitud, estilo)\")\n",
    "    print(\"   4. S√© claro y espec√≠fico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 18: Formato de salida estructurado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Crea un prompt que fuerce una salida en formato tabla\n",
    "\n",
    "# Escribe tu prompt aqu√≠:\n",
    "prompt_tabla = \"\"\"\n",
    "Create a comparison table of: Python, Java, and JavaScript.\n",
    "Format:\n",
    "Language | Paradigm | Key Advantage\n",
    "---------|-----------|--------------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if prompt_tabla:\n",
    "    print(\"üéØ Tu prompt:\")\n",
    "    print(prompt_tabla)\n",
    "    print(\"\\n\" + \"=\"*90 + \"\\n\")\n",
    "    \n",
    "    respuesta = generar_respuesta(prompt_tabla, max_len=120, temp=0.5)\n",
    "    print(\"üìä Salida generada:\\n\")\n",
    "    print(respuesta)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Define un prompt en 'prompt_tabla' que fuerce salida estructurada\")\n",
    "    print(\"\\nüí° Intenta formatos como:\")\n",
    "    print(\"   - Tablas (con | como separador)\")\n",
    "    print(\"   - Listas numeradas (1., 2., 3.)\")\n",
    "    print(\"   - Listas con bullets (-, *, ‚Ä¢)\")\n",
    "    print(\"   - JSON-like structures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù EJERCICIO 19: Few-shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO: Usa ejemplos para guiar al modelo (few-shot)\n",
    "\n",
    "# Tarea: Clasificaci√≥n de emociones m√°s all√° de positivo/negativo\n",
    "prompt_fewshot = \"\"\"Classify the emotion in each text as: Joy, Sadness, Anger, Fear, or Neutral.\n",
    "\n",
    "Examples:\n",
    "Text: \"I'm so happy today, everything is perfect!\"\n",
    "Emotion: Joy\n",
    "\n",
    "Text: \"I'm terrified of what might happen.\"\n",
    "Emotion: Fear\n",
    "\n",
    "Text: \"This makes me so furious!\"\n",
    "Emotion: Anger\n",
    "\n",
    "Now classify this:\n",
    "Text: \"I miss my old friends, those were good times.\"\n",
    "Emotion:\"\"\"\n",
    "\n",
    "print(\"üéì Few-shot Learning - Clasificaci√≥n de Emociones\\n\")\n",
    "print(\"=\"*90)\n",
    "print(\"\\nüìù Prompt (con ejemplos):\")\n",
    "print(prompt_fewshot)\n",
    "print(\"\\n\" + \"-\"*90 + \"\\n\")\n",
    "\n",
    "respuesta = generar_respuesta(prompt_fewshot, max_len=150, temp=0.3)\n",
    "print(\"ü§ñ Respuesta del modelo:\\n\")\n",
    "print(respuesta)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"\\nüí° Observa c√≥mo los ejemplos gu√≠an al modelo hacia el formato deseado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
