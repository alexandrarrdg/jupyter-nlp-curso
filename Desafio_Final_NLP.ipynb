{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Desaf√≠o Final: Sistema Inteligente de Procesamiento de Lenguaje Natural\n",
    "\n",
    "## Bienvenido al Proyecto Final del Curso\n",
    "\n",
    "Este notebook contiene el desaf√≠o final del curso de NLP y LLMs. Tu objetivo es construir un **sistema completo de procesamiento de lenguaje natural** que integre todas las t√©cnicas aprendidas.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Objetivos del Proyecto\n",
    "\n",
    "Construir un sistema que combine:\n",
    "\n",
    "1. **NLP Cl√°sico**: Preprocesamiento y an√°lisis de texto\n",
    "2. **Embeddings**: Representaci√≥n sem√°ntica de documentos\n",
    "3. **Clasificaci√≥n con BERT**: Categorizaci√≥n autom√°tica\n",
    "4. **Sistema RAG**: Recuperaci√≥n y generaci√≥n aumentada\n",
    "5. **Generaci√≥n con GPT**: Creaci√≥n de contenido inteligente\n",
    "6. **Agente Inteligente**: Orquestaci√≥n y automatizaci√≥n\n",
    "\n",
    "---\n",
    "\n",
    "## üé® Opciones de Proyecto\n",
    "\n",
    "Puedes elegir uno de estos dominios para tu proyecto:\n",
    "\n",
    "### Opci√≥n A: üìö Asistente de Investigaci√≥n Acad√©mica\n",
    "- Procesa papers cient√≠ficos\n",
    "- Clasifica por √°rea de investigaci√≥n\n",
    "- Sistema Q&A sobre documentos\n",
    "- Genera res√∫menes autom√°ticos\n",
    "\n",
    "### Opci√≥n B: üì∞ Analizador de Noticias Inteligente\n",
    "- Procesa art√≠culos de prensa\n",
    "- Clasifica por tema y sentimiento\n",
    "- Busca noticias relacionadas\n",
    "- Genera res√∫menes personalizados\n",
    "\n",
    "### Opci√≥n C: üí¨ Asistente de Atenci√≥n al Cliente\n",
    "- Procesa consultas de usuarios\n",
    "- Clasifica por categor√≠a y urgencia\n",
    "- Recupera informaci√≥n relevante\n",
    "- Genera respuestas autom√°ticas\n",
    "\n",
    "### Opci√≥n D: üéì Tu Propio Proyecto\n",
    "- Define tu dominio de aplicaci√≥n\n",
    "- Debe incluir los 6 componentes principales\n",
    "- Explica claramente el caso de uso\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Criterios de Evaluaci√≥n\n",
    "\n",
    "Tu proyecto ser√° evaluado seg√∫n:\n",
    "\n",
    "| Componente | Puntos | Criterios |\n",
    "|------------|--------|----------|\n",
    "| **1. NLP Cl√°sico** | 15% | Preprocesamiento completo y an√°lisis exploratorio |\n",
    "| **2. Embeddings** | 15% | Implementaci√≥n de b√∫squeda sem√°ntica funcional |\n",
    "| **3. Clasificaci√≥n BERT** | 20% | Modelo entrenado/fine-tuned con buena precisi√≥n |\n",
    "| **4. Sistema RAG** | 20% | Pipeline completo de recuperaci√≥n + generaci√≥n |\n",
    "| **5. Generaci√≥n GPT** | 15% | Generaci√≥n de texto coherente y √∫til |\n",
    "| **6. Agente** | 10% | Orquestaci√≥n inteligente de componentes |\n",
    "| **7. Documentaci√≥n** | 5% | C√≥digo comentado y explicaciones claras |\n",
    "\n",
    "**Total: 100 puntos**\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Instrucciones de Entrega\n",
    "\n",
    "### Opci√≥n 1: Google Colab (Recomendado)\n",
    "\n",
    "1. **Guarda tu notebook en Colab**:\n",
    "   - `Archivo ‚Üí Guardar una copia en Drive`\n",
    "\n",
    "2. **Comparte el enlace**:\n",
    "   - Click en `Compartir` (bot√≥n superior derecho)\n",
    "   - Cambia a `Cualquier persona con el enlace`\n",
    "   - Copia el enlace\n",
    "\n",
    "3. **Aseg√∫rate de que sea ejecutable**:\n",
    "   - Ejecuta todas las celdas: `Entorno de ejecuci√≥n ‚Üí Ejecutar todas`\n",
    "   - Verifica que no haya errores\n",
    "\n",
    "### Opci√≥n 2: GitHub\n",
    "\n",
    "1. **Crea un repositorio**:\n",
    "   ```bash\n",
    "   git init\n",
    "   git add Desafio_Final_NLP.ipynb\n",
    "   git commit -m \"Proyecto final NLP\"\n",
    "   ```\n",
    "\n",
    "2. **Sube a GitHub**:\n",
    "   - Crea repo en github.com\n",
    "   - Conecta y sube:\n",
    "   ```bash\n",
    "   git remote add origin [tu-repo-url]\n",
    "   git push -u origin main\n",
    "   ```\n",
    "\n",
    "3. **A√±ade un README.md**:\n",
    "   - Explica tu proyecto\n",
    "   - Instrucciones de ejecuci√≥n\n",
    "   - Resultados principales\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è∞ Tiempo Estimado\n",
    "\n",
    "- **Planificaci√≥n y dise√±o**: 30 minutos\n",
    "- **Implementaci√≥n**: 3-4 horas\n",
    "- **Pruebas y ajustes**: 1 hora\n",
    "- **Documentaci√≥n**: 30 minutos\n",
    "\n",
    "**Total: 5-6 horas**\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ ¬°Comencemos!\n",
    "\n",
    "En las siguientes secciones encontrar√°s el template guiado para construir tu proyecto paso a paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìù Secci√≥n 0: Definici√≥n de tu Proyecto\n",
    "\n",
    "**Completa esta secci√≥n antes de comenzar a programar**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mi Proyecto\n",
    "\n",
    "**T√≠tulo**: [Escribe aqu√≠ el nombre de tu proyecto]\n",
    "\n",
    "**Opci√≥n elegida**: [A, B, C, o D]\n",
    "\n",
    "**Descripci√≥n del problema**:\n",
    "[Explica en 2-3 p√°rrafos qu√© problema resuelve tu sistema y por qu√© es √∫til]\n",
    "\n",
    "**Fuente de datos**:\n",
    "[Describe qu√© tipo de textos vas a procesar. Pueden ser datasets p√∫blicos o textos que t√∫ mismo recopiles]\n",
    "\n",
    "**Funcionalidades principales**:\n",
    "1. [Funcionalidad 1]\n",
    "2. [Funcionalidad 2]\n",
    "3. [Funcionalidad 3]\n",
    "4. [Funcionalidad 4]\n",
    "\n",
    "**Casos de uso ejemplo**:\n",
    "1. [Ejemplo concreto de uso 1]\n",
    "2. [Ejemplo concreto de uso 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üîß Secci√≥n 1: Instalaci√≥n y Configuraci√≥n\n",
    "\n",
    "Instala todas las bibliotecas necesarias para tu proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de bibliotecas principales\n",
    "!pip install -q transformers sentence-transformers datasets torch scikit-learn pandas numpy matplotlib seaborn nltk spacy\n",
    "\n",
    "# Descarga de recursos de NLP\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "print(\"‚úÖ Instalaci√≥n completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# NLP Cl√°sico\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Transformers y embeddings\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Importaciones completadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìä Secci√≥n 2: Datos y Preprocesamiento (NLP Cl√°sico)\n",
    "\n",
    "**Objetivos**:\n",
    "1. Cargar o crear tu dataset de textos\n",
    "2. Implementar pipeline completo de preprocesamiento\n",
    "3. An√°lisis exploratorio de los datos\n",
    "\n",
    "**Puntos: 15/100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 1: Carga de Datos\n",
    "# Opci√≥n A: Usar un dataset p√∫blico (recomendado para empezar)\n",
    "# Opci√≥n B: Crear tu propio dataset\n",
    "\n",
    "# EJEMPLO: Dataset de papers acad√©micos (Opci√≥n A)\n",
    "# Puedes usar datasets de Hugging Face, cargar CSVs, o scraping web\n",
    "\n",
    "# Aqu√≠ hay ejemplos de datasets que puedes usar:\n",
    "# - Para noticias: from datasets import load_dataset; dataset = load_dataset(\"multi_news\")\n",
    "# - Para papers: arxiv, pubmed\n",
    "# - Para reviews: amazon_reviews, yelp\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Carga al menos 50-100 documentos de texto\n",
    "\n",
    "# EJEMPLO (reemplaza con tu propio c√≥digo):\n",
    "documentos = [\n",
    "    \"Tu primer documento aqu√≠...\",\n",
    "    \"Tu segundo documento...\",\n",
    "    # ... a√±ade m√°s documentos\n",
    "]\n",
    "\n",
    "# Metadatos asociados (etiquetas, categor√≠as, etc.)\n",
    "metadatos = [\n",
    "    {\"categoria\": \"ejemplo1\", \"fecha\": \"2024-01-01\"},\n",
    "    {\"categoria\": \"ejemplo2\", \"fecha\": \"2024-01-02\"},\n",
    "    # ...\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Cargados {len(documentos)} documentos\")\n",
    "print(f\"Ejemplo: {documentos[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 2: Pipeline de Preprocesamiento\n",
    "# Implementa funciones de limpieza y normalizaci√≥n\n",
    "\n",
    "class PreprocessorNLP:\n",
    "    def __init__(self, idioma='spanish'):\n",
    "        self.idioma = idioma\n",
    "        self.stopwords = set(stopwords.words(idioma))\n",
    "        self.stemmer = SnowballStemmer(idioma)\n",
    "    \n",
    "    def limpiar_texto(self, texto):\n",
    "        \"\"\"\n",
    "        Limpia el texto eliminando caracteres especiales, URLs, etc.\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        # Tu c√≥digo aqu√≠:\n",
    "        # - Convertir a min√∫sculas\n",
    "        # - Eliminar URLs\n",
    "        # - Eliminar emails\n",
    "        # - Eliminar caracteres especiales\n",
    "        # - Eliminar n√∫meros (opcional)\n",
    "        # - Eliminar espacios extra\n",
    "        \n",
    "        texto_limpio = texto  # REEMPLAZA ESTO\n",
    "        return texto_limpio\n",
    "    \n",
    "    def tokenizar(self, texto):\n",
    "        \"\"\"\n",
    "        Tokeniza el texto en palabras\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        # Tu c√≥digo aqu√≠\n",
    "        tokens = []  # REEMPLAZA ESTO\n",
    "        return tokens\n",
    "    \n",
    "    def eliminar_stopwords(self, tokens):\n",
    "        \"\"\"\n",
    "        Elimina palabras vac√≠as\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        # Tu c√≥digo aqu√≠\n",
    "        tokens_filtrados = []  # REEMPLAZA ESTO\n",
    "        return tokens_filtrados\n",
    "    \n",
    "    def aplicar_stemming(self, tokens):\n",
    "        \"\"\"\n",
    "        Aplica stemming a los tokens\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        # Tu c√≥digo aqu√≠\n",
    "        stems = []  # REEMPLAZA ESTO\n",
    "        return stems\n",
    "    \n",
    "    def preprocesar(self, texto, eliminar_sw=True, aplicar_stem=False):\n",
    "        \"\"\"\n",
    "        Pipeline completo de preprocesamiento\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN integrando las anteriores\n",
    "        \"\"\"\n",
    "        # Tu c√≥digo aqu√≠: combina todas las funciones anteriores\n",
    "        tokens_procesados = []  # REEMPLAZA ESTO\n",
    "        return tokens_procesados\n",
    "\n",
    "# Prueba tu preprocessor\n",
    "preprocessor = PreprocessorNLP(idioma='spanish')  # Cambia seg√∫n tu idioma\n",
    "\n",
    "# Ejemplo de uso\n",
    "texto_ejemplo = \"Este es un texto de EJEMPLO con URLs https://ejemplo.com y n√∫meros 12345!\"\n",
    "resultado = preprocessor.preprocesar(texto_ejemplo)\n",
    "print(f\"Texto original: {texto_ejemplo}\")\n",
    "print(f\"Tokens procesados: {resultado}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 3: Procesa todos tus documentos\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Aplica el preprocessor a todos tus documentos\n",
    "# Guarda tanto el texto original como el procesado\n",
    "\n",
    "documentos_procesados = []\n",
    "\n",
    "# Ejemplo:\n",
    "# for doc in documentos:\n",
    "#     tokens = preprocessor.preprocesar(doc)\n",
    "#     documentos_procesados.append(tokens)\n",
    "\n",
    "print(f\"‚úÖ Procesados {len(documentos_procesados)} documentos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 4: An√°lisis Exploratorio\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Crea visualizaciones para entender tus datos:\n",
    "\n",
    "# 1. Distribuci√≥n de longitud de documentos\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# ...\n",
    "\n",
    "# 2. Palabras m√°s frecuentes (nube de palabras o gr√°fico de barras)\n",
    "# ...\n",
    "\n",
    "# 3. Distribuci√≥n de categor√≠as (si aplica)\n",
    "# ...\n",
    "\n",
    "# 4. Estad√≠sticas descriptivas\n",
    "# ...\n",
    "\n",
    "print(\"üìä An√°lisis exploratorio completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üî¢ Secci√≥n 3: Sistema de Embeddings y B√∫squeda Sem√°ntica\n",
    "\n",
    "**Objetivos**:\n",
    "1. Generar embeddings de tus documentos\n",
    "2. Implementar b√∫squeda por similitud sem√°ntica\n",
    "3. Crear √≠ndice de documentos\n",
    "\n",
    "**Puntos: 15/100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 5: Cargar modelo de embeddings\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Carga un modelo de sentence-transformers apropiado para tu idioma\n",
    "# Opciones:\n",
    "# - Multiling√ºe: 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "# - Espa√±ol: 'hiiamsid/sentence_similarity_spanish_es'\n",
    "# - Ingl√©s: 'all-MiniLM-L6-v2'\n",
    "\n",
    "# modelo_embeddings = SentenceTransformer('...')\n",
    "\n",
    "print(\"‚úÖ Modelo de embeddings cargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 6: Generar embeddings de documentos\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Genera embeddings para todos tus documentos\n",
    "# Gu√°rdalos en una matriz numpy para b√∫squeda eficiente\n",
    "\n",
    "# embeddings_documentos = modelo_embeddings.encode(documentos, show_progress_bar=True)\n",
    "\n",
    "# print(f\"‚úÖ Generados embeddings de forma {embeddings_documentos.shape}\")\n",
    "# print(f\"   - {embeddings_documentos.shape[0]} documentos\")\n",
    "# print(f\"   - {embeddings_documentos.shape[1]} dimensiones por embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 7: Implementar b√∫squeda sem√°ntica\n",
    "\n",
    "class BuscadorSemantico:\n",
    "    def __init__(self, documentos, embeddings, modelo):\n",
    "        self.documentos = documentos\n",
    "        self.embeddings = embeddings\n",
    "        self.modelo = modelo\n",
    "    \n",
    "    def buscar(self, consulta, top_k=5):\n",
    "        \"\"\"\n",
    "        Busca los documentos m√°s similares a la consulta\n",
    "        \n",
    "        Args:\n",
    "            consulta: texto de b√∫squeda\n",
    "            top_k: n√∫mero de resultados a retornar\n",
    "        \n",
    "        Returns:\n",
    "            Lista de tuplas (documento, score, √≠ndice)\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        # Tu c√≥digo aqu√≠:\n",
    "        # 1. Generar embedding de la consulta\n",
    "        # 2. Calcular similitud coseno con todos los documentos\n",
    "        # 3. Ordenar por similitud\n",
    "        # 4. Retornar top_k resultados\n",
    "        \n",
    "        resultados = []  # REEMPLAZA ESTO\n",
    "        return resultados\n",
    "    \n",
    "    def mostrar_resultados(self, resultados):\n",
    "        \"\"\"\n",
    "        Muestra los resultados de b√∫squeda de forma legible\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        # Tu c√≥digo aqu√≠\n",
    "        pass\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Crea una instancia del buscador y pru√©balo\n",
    "\n",
    "# buscador = BuscadorSemantico(documentos, embeddings_documentos, modelo_embeddings)\n",
    "# resultados = buscador.buscar(\"tu consulta de prueba\")\n",
    "# buscador.mostrar_resultados(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 8: Pruebas de b√∫squeda\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Realiza al menos 3 b√∫squedas diferentes y analiza los resultados\n",
    "# Verifica que la b√∫squeda sem√°ntica funcione correctamente\n",
    "\n",
    "consultas_prueba = [\n",
    "    \"tu primera consulta\",\n",
    "    \"tu segunda consulta\",\n",
    "    \"tu tercera consulta\"\n",
    "]\n",
    "\n",
    "# for consulta in consultas_prueba:\n",
    "#     print(f\"\\nüîç Consulta: {consulta}\")\n",
    "#     resultados = buscador.buscar(consulta, top_k=3)\n",
    "#     buscador.mostrar_resultados(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéØ Secci√≥n 4: Clasificaci√≥n con BERT\n",
    "\n",
    "**Objetivos**:\n",
    "1. Preparar datos etiquetados para clasificaci√≥n\n",
    "2. Fine-tuning de BERT o usar modelo pre-entrenado\n",
    "3. Evaluar rendimiento del clasificador\n",
    "\n",
    "**Puntos: 20/100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 9: Preparar datos de clasificaci√≥n\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Define las categor√≠as/clases para tu proyecto\n",
    "# Aseg√∫rate de tener datos etiquetados (al menos 20-30 ejemplos por clase)\n",
    "\n",
    "# Opci√≥n A: Usar pipeline de clasificaci√≥n pre-entrenado\n",
    "# (m√°s f√°cil, pero menos personalizado)\n",
    "\n",
    "# Opci√≥n B: Fine-tuning de BERT\n",
    "# (m√°s complejo, pero mejor rendimiento en tu dominio)\n",
    "\n",
    "# Ejemplo de estructura de datos:\n",
    "datos_clasificacion = [\n",
    "    {\"texto\": \"ejemplo 1\", \"etiqueta\": \"categoria_1\"},\n",
    "    {\"texto\": \"ejemplo 2\", \"etiqueta\": \"categoria_2\"},\n",
    "    # ...\n",
    "]\n",
    "\n",
    "# Convierte a DataFrame\n",
    "# df_clasificacion = pd.DataFrame(datos_clasificacion)\n",
    "\n",
    "print(\"üìä Datos de clasificaci√≥n preparados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 10: Implementar clasificador\n",
    "\n",
    "# OPCI√ìN A: Clasificador pre-entrenado (recomendado para empezar)\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Usa un pipeline de clasificaci√≥n apropiado para tu tarea\n",
    "# Ejemplos:\n",
    "# - Sentimiento: pipeline(\"sentiment-analysis\", model=\"...\")\n",
    "# - Zero-shot: pipeline(\"zero-shot-classification\", model=\"...\")\n",
    "\n",
    "# clasificador = pipeline(\"...\", model=\"...\")\n",
    "\n",
    "print(\"‚úÖ Clasificador listo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCI√ìN B: Fine-tuning de BERT (avanzado)\n",
    "\n",
    "# Si eliges esta opci√≥n, necesitar√°s:\n",
    "# 1. Preparar dataset con train/validation split\n",
    "# 2. Tokenizar los textos\n",
    "# 3. Cargar modelo BERT para clasificaci√≥n\n",
    "# 4. Entrenar el modelo\n",
    "# 5. Evaluar y guardar\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç (opcional):\n",
    "\n",
    "# from transformers import TrainingArguments, Trainer\n",
    "# from datasets import Dataset\n",
    "\n",
    "# Ejemplo de estructura:\n",
    "# 1. Tokenizaci√≥n\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"texto\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# 2. Modelo\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"dccuchile/bert-base-spanish-wwm-cased\",\n",
    "#     num_labels=len(categorias)\n",
    "# )\n",
    "\n",
    "# 3. Training\n",
    "# training_args = TrainingArguments(...)\n",
    "# trainer = Trainer(...)\n",
    "# trainer.train()\n",
    "\n",
    "print(\"‚ö†Ô∏è Fine-tuning completado (si elegiste esta opci√≥n)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 11: Evaluar clasificador\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Clasifica tus documentos y eval√∫a el rendimiento\n",
    "\n",
    "# 1. Clasificar documentos\n",
    "# predicciones = []\n",
    "# for doc in documentos:\n",
    "#     pred = clasificador(doc)\n",
    "#     predicciones.append(pred)\n",
    "\n",
    "# 2. Matriz de confusi√≥n (si tienes etiquetas verdaderas)\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# ...\n",
    "\n",
    "# 3. Visualizaci√≥n de resultados\n",
    "# ...\n",
    "\n",
    "print(\"üìä Evaluaci√≥n del clasificador completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üîÑ Secci√≥n 5: Sistema RAG (Retrieval Augmented Generation)\n",
    "\n",
    "**Objetivos**:\n",
    "1. Integrar b√∫squeda sem√°ntica con generaci√≥n\n",
    "2. Implementar pipeline RAG completo\n",
    "3. Generar respuestas basadas en contexto recuperado\n",
    "\n",
    "**Puntos: 20/100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 12: Cargar modelo generativo\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Carga un modelo de generaci√≥n de texto\n",
    "# Opciones seg√∫n tus recursos:\n",
    "# - Liviano: \"gpt2\", \"distilgpt2\"\n",
    "# - Espa√±ol: \"DeepESP/gpt2-spanish\"\n",
    "# - Multiling√ºe: \"bigscience/bloom-560m\"\n",
    "\n",
    "# generador = pipeline(\"text-generation\", model=\"...\")\n",
    "\n",
    "print(\"‚úÖ Modelo generativo cargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 13: Implementar sistema RAG\n",
    "\n",
    "class SistemaRAG:\n",
    "    def __init__(self, buscador, generador):\n",
    "        self.buscador = buscador\n",
    "        self.generador = generador\n",
    "    \n",
    "    def generar_respuesta(self, pregunta, top_k=3, usar_contexto=True):\n",
    "        \"\"\"\n",
    "        Pipeline RAG completo:\n",
    "        1. Recuperar documentos relevantes (Retrieval)\n",
    "        2. Construir prompt con contexto (Augmentation)\n",
    "        3. Generar respuesta (Generation)\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        \n",
    "        # Paso 1: Recuperaci√≥n\n",
    "        if usar_contexto:\n",
    "            # Tu c√≥digo aqu√≠:\n",
    "            # - Buscar documentos relevantes\n",
    "            # - Extraer el texto de los documentos\n",
    "            contexto = \"\"  # REEMPLAZA ESTO\n",
    "        else:\n",
    "            contexto = \"\"\n",
    "        \n",
    "        # Paso 2: Augmentaci√≥n (construcci√≥n del prompt)\n",
    "        if usar_contexto:\n",
    "            prompt = f\"\"\"Contexto:\n",
    "{contexto}\n",
    "\n",
    "Pregunta: {pregunta}\n",
    "\n",
    "Respuesta basada en el contexto anterior:\"\"\"\n",
    "        else:\n",
    "            prompt = f\"Pregunta: {pregunta}\\n\\nRespuesta:\"\n",
    "        \n",
    "        # Paso 3: Generaci√≥n\n",
    "        # Tu c√≥digo aqu√≠:\n",
    "        # - Generar respuesta usando el modelo\n",
    "        # - Procesar y limpiar la respuesta\n",
    "        respuesta = \"\"  # REEMPLAZA ESTO\n",
    "        \n",
    "        return {\n",
    "            \"pregunta\": pregunta,\n",
    "            \"respuesta\": respuesta,\n",
    "            \"contexto_usado\": contexto if usar_contexto else None,\n",
    "            \"documentos_fuente\": []  # Lista de documentos usados\n",
    "        }\n",
    "    \n",
    "    def comparar_con_sin_contexto(self, pregunta):\n",
    "        \"\"\"\n",
    "        Compara respuestas con y sin RAG\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        # Tu c√≥digo aqu√≠\n",
    "        pass\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Crea instancia del sistema RAG\n",
    "\n",
    "# sistema_rag = SistemaRAG(buscador, generador)\n",
    "\n",
    "print(\"‚úÖ Sistema RAG inicializado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 14: Pruebas del sistema RAG\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Realiza al menos 3 preguntas a tu sistema RAG\n",
    "# Compara respuestas con y sin contexto\n",
    "\n",
    "preguntas_prueba = [\n",
    "    \"tu primera pregunta relacionada con tus documentos\",\n",
    "    \"tu segunda pregunta\",\n",
    "    \"tu tercera pregunta\"\n",
    "]\n",
    "\n",
    "# for pregunta in preguntas_prueba:\n",
    "#     print(f\"\\n‚ùì {pregunta}\")\n",
    "#     print(\"=\"*80)\n",
    "#     \n",
    "#     # Sin RAG\n",
    "#     resp_sin = sistema_rag.generar_respuesta(pregunta, usar_contexto=False)\n",
    "#     print(f\"\\nü§ñ Sin contexto: {resp_sin['respuesta']}\")\n",
    "#     \n",
    "#     # Con RAG\n",
    "#     resp_con = sistema_rag.generar_respuesta(pregunta, usar_contexto=True)\n",
    "#     print(f\"\\nüéØ Con RAG: {resp_con['respuesta']}\")\n",
    "#     print(f\"\\nüìö Fuentes: {len(resp_con['documentos_fuente'])} documentos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚úçÔ∏è Secci√≥n 6: Generaci√≥n Avanzada con GPT\n",
    "\n",
    "**Objetivos**:\n",
    "1. Generar contenido original basado en tus documentos\n",
    "2. Implementar diferentes estrategias de generaci√≥n\n",
    "3. Crear utilidades √∫tiles (res√∫menes, expansiones, etc.)\n",
    "\n",
    "**Puntos: 15/100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 15: Implementar generador avanzado\n",
    "\n",
    "class GeneradorInteligente:\n",
    "    def __init__(self, modelo_generacion):\n",
    "        self.modelo = modelo_generacion\n",
    "    \n",
    "    def generar_resumen(self, texto, max_length=100):\n",
    "        \"\"\"\n",
    "        Genera un resumen del texto\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        # Opci√≥n A: Usar modelo de summarization\n",
    "        # Opci√≥n B: Usar generaci√≥n con prompt espec√≠fico\n",
    "        \n",
    "        resumen = \"\"  # REEMPLAZA ESTO\n",
    "        return resumen\n",
    "    \n",
    "    def expandir_texto(self, texto_semilla, num_palabras=200):\n",
    "        \"\"\"\n",
    "        Expande un texto inicial generando continuaci√≥n\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        expansion = \"\"  # REEMPLAZA ESTO\n",
    "        return expansion\n",
    "    \n",
    "    def generar_con_estilo(self, prompt, temperatura=0.7, top_p=0.9):\n",
    "        \"\"\"\n",
    "        Genera texto con par√°metros personalizados\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        # Experimenta con diferentes valores de temperatura y top_p\n",
    "        texto_generado = \"\"  # REEMPLAZA ESTO\n",
    "        return texto_generado\n",
    "    \n",
    "    def generar_variaciones(self, texto_base, num_variaciones=3):\n",
    "        \"\"\"\n",
    "        Genera m√∫ltiples variaciones de un texto\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        variaciones = []  # REEMPLAZA ESTO\n",
    "        return variaciones\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Crea instancia del generador\n",
    "\n",
    "# generador_avanzado = GeneradorInteligente(generador)\n",
    "\n",
    "print(\"‚úÖ Generador avanzado inicializado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 16: Casos de uso de generaci√≥n\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Implementa al menos 2 casos de uso espec√≠ficos para tu proyecto\n",
    "# Ejemplos:\n",
    "# - Generar res√∫menes de documentos largos\n",
    "# - Crear t√≠tulos autom√°ticos\n",
    "# - Generar conclusiones\n",
    "# - Escribir introducciones\n",
    "# - Parafrasear contenido\n",
    "\n",
    "# Caso de uso 1:\n",
    "print(\"üìù Caso de uso 1: [describe tu caso]\")\n",
    "# Tu c√≥digo aqu√≠\n",
    "\n",
    "# Caso de uso 2:\n",
    "print(\"\\nüìù Caso de uso 2: [describe tu caso]\")\n",
    "# Tu c√≥digo aqu√≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ü§ñ Secci√≥n 7: Agente Inteligente\n",
    "\n",
    "**Objetivos**:\n",
    "1. Orquestar todos los componentes anteriores\n",
    "2. Implementar flujo de decisi√≥n inteligente\n",
    "3. Crear interfaz unificada del sistema\n",
    "\n",
    "**Puntos: 10/100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 17: Implementar agente integrador\n",
    "\n",
    "class AgenteNLP:\n",
    "    \"\"\"\n",
    "    Agente que orquesta todos los componentes del sistema\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, preprocessor, buscador, clasificador, sistema_rag, generador):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.buscador = buscador\n",
    "        self.clasificador = clasificador\n",
    "        self.sistema_rag = sistema_rag\n",
    "        self.generador = generador\n",
    "    \n",
    "    def procesar_consulta(self, consulta_usuario):\n",
    "        \"\"\"\n",
    "        Decide qu√© operaci√≥n realizar bas√°ndose en la consulta\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \n",
    "        Ideas de flujo:\n",
    "        1. Analizar la intenci√≥n de la consulta\n",
    "        2. Decidir qu√© componente(s) usar\n",
    "        3. Ejecutar las operaciones necesarias\n",
    "        4. Combinar resultados\n",
    "        5. Presentar respuesta final\n",
    "        \"\"\"\n",
    "        \n",
    "        resultado = {\n",
    "            \"consulta\": consulta_usuario,\n",
    "            \"operaciones_realizadas\": [],\n",
    "            \"resultados\": {},\n",
    "            \"respuesta_final\": \"\"\n",
    "        }\n",
    "        \n",
    "        # Tu c√≥digo aqu√≠:\n",
    "        # Ejemplo de flujo de decisi√≥n:\n",
    "        # - Si contiene \"busca\" o \"encuentra\" ‚Üí usar buscador\n",
    "        # - Si pide \"clasificar\" o \"categorizar\" ‚Üí usar clasificador\n",
    "        # - Si hace pregunta ‚Üí usar RAG\n",
    "        # - Si pide \"generar\" o \"crear\" ‚Üí usar generador\n",
    "        # - Combinar m√∫ltiples operaciones si es necesario\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def ejecutar_flujo_completo(self, entrada_usuario):\n",
    "        \"\"\"\n",
    "        Flujo completo que usa todos los componentes\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \n",
    "        Ejemplo de flujo:\n",
    "        1. Preprocesar entrada\n",
    "        2. Buscar documentos relevantes\n",
    "        3. Clasificar la consulta\n",
    "        4. Generar respuesta con RAG\n",
    "        5. Refinar respuesta con generador\n",
    "        \"\"\"\n",
    "        \n",
    "        # Tu c√≥digo aqu√≠\n",
    "        pass\n",
    "    \n",
    "    def modo_conversacional(self):\n",
    "        \"\"\"\n",
    "        Modo interactivo para probar el agente\n",
    "        \n",
    "        üëâ COMPLETA ESTA FUNCI√ìN\n",
    "        \"\"\"\n",
    "        print(\"ü§ñ Agente NLP iniciado. Escribe 'salir' para terminar.\\n\")\n",
    "        \n",
    "        while True:\n",
    "            # Tu c√≥digo aqu√≠:\n",
    "            # - Solicitar entrada del usuario\n",
    "            # - Procesar la consulta\n",
    "            # - Mostrar resultados\n",
    "            # - Permitir salir\n",
    "            pass\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Crea instancia del agente con todos tus componentes\n",
    "\n",
    "# agente = AgenteNLP(\n",
    "#     preprocessor=preprocessor,\n",
    "#     buscador=buscador,\n",
    "#     clasificador=clasificador,\n",
    "#     sistema_rag=sistema_rag,\n",
    "#     generador=generador_avanzado\n",
    "# )\n",
    "\n",
    "print(\"‚úÖ Agente NLP creado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 18: Pruebas del agente\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Prueba tu agente con diferentes tipos de consultas\n",
    "\n",
    "consultas_prueba = [\n",
    "    \"tu consulta de b√∫squeda\",\n",
    "    \"tu consulta de clasificaci√≥n\",\n",
    "    \"tu pregunta para RAG\",\n",
    "    \"tu solicitud de generaci√≥n\",\n",
    "]\n",
    "\n",
    "# for consulta in consultas_prueba:\n",
    "#     print(f\"\\n{'='*80}\")\n",
    "#     print(f\"Usuario: {consulta}\")\n",
    "#     print(f\"{'='*80}\")\n",
    "#     \n",
    "#     resultado = agente.procesar_consulta(consulta)\n",
    "#     # Muestra los resultados\n",
    "#     print(f\"\\n{resultado}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù OPCIONAL: Modo conversacional\n",
    "\n",
    "# Descomenta para activar el modo interactivo:\n",
    "# agente.modo_conversacional()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìä Secci√≥n 8: Demo y Documentaci√≥n Final\n",
    "\n",
    "**Objetivos**:\n",
    "1. Crear demo completa del sistema\n",
    "2. Documentar arquitectura y componentes\n",
    "3. An√°lisis de resultados y conclusiones\n",
    "\n",
    "**Puntos: 5/100**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé¨ Demo Completa\n",
    "\n",
    "**Instrucciones**:\n",
    "\n",
    "Crea una demostraci√≥n completa de tu sistema que muestre:\n",
    "\n",
    "1. **Presentaci√≥n del problema**: Qu√© problema resuelve tu sistema\n",
    "2. **Datos utilizados**: Descripci√≥n de tu corpus de documentos\n",
    "3. **Componentes del sistema**: Explicaci√≥n de cada m√≥dulo\n",
    "4. **Casos de uso**: 3-5 ejemplos reales de uso\n",
    "5. **Resultados**: M√©tricas de rendimiento cuando aplique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù EJERCICIO 19: Demo completa\n",
    "\n",
    "# üëâ TU C√ìDIGO AQU√ç:\n",
    "# Crea una funci√≥n que ejecute una demo completa de tu sistema\n",
    "\n",
    "def demo_sistema_completo():\n",
    "    \"\"\"\n",
    "    Demostraci√≥n completa del sistema NLP\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"üéØ DEMO: [NOMBRE DE TU PROYECTO]\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Presentaci√≥n\n",
    "    print(\"\\nüìã DESCRIPCI√ìN DEL PROBLEMA\")\n",
    "    print(\"-\"*80)\n",
    "    # Tu descripci√≥n aqu√≠\n",
    "    \n",
    "    # 2. Datos\n",
    "    print(\"\\nüìä DATOS UTILIZADOS\")\n",
    "    print(\"-\"*80)\n",
    "    # Estad√≠sticas de tus datos\n",
    "    \n",
    "    # 3. Componentes\n",
    "    print(\"\\nüîß COMPONENTES DEL SISTEMA\")\n",
    "    print(\"-\"*80)\n",
    "    # Lista tus componentes\n",
    "    \n",
    "    # 4. Casos de uso\n",
    "    print(\"\\nüí° CASOS DE USO\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Caso 1: B√∫squeda sem√°ntica\n",
    "    print(\"\\n1Ô∏è‚É£ B√∫squeda Sem√°ntica\")\n",
    "    # Tu demo aqu√≠\n",
    "    \n",
    "    # Caso 2: Clasificaci√≥n\n",
    "    print(\"\\n2Ô∏è‚É£ Clasificaci√≥n Autom√°tica\")\n",
    "    # Tu demo aqu√≠\n",
    "    \n",
    "    # Caso 3: Sistema RAG\n",
    "    print(\"\\n3Ô∏è‚É£ Sistema de Pregunta-Respuesta (RAG)\")\n",
    "    # Tu demo aqu√≠\n",
    "    \n",
    "    # Caso 4: Generaci√≥n\n",
    "    print(\"\\n4Ô∏è‚É£ Generaci√≥n de Contenido\")\n",
    "    # Tu demo aqu√≠\n",
    "    \n",
    "    # Caso 5: Agente completo\n",
    "    print(\"\\n5Ô∏è‚É£ Agente Inteligente\")\n",
    "    # Tu demo aqu√≠\n",
    "    \n",
    "    # 5. M√©tricas\n",
    "    print(\"\\nüìà M√âTRICAS DE RENDIMIENTO\")\n",
    "    print(\"-\"*80)\n",
    "    # Tus m√©tricas aqu√≠\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ DEMO COMPLETADA\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Ejecuta la demo\n",
    "# demo_sistema_completo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìê Arquitectura del Sistema\n",
    "\n",
    "**Documenta aqu√≠ la arquitectura de tu sistema**:\n",
    "\n",
    "### Diagrama de Componentes\n",
    "\n",
    "```\n",
    "[Dibuja o describe el flujo de datos entre componentes]\n",
    "\n",
    "Entrada del Usuario\n",
    "        ‚Üì\n",
    "   Preprocessor\n",
    "        ‚Üì\n",
    "    Agente NLP\n",
    "        ‚Üì\n",
    "   [Componentes]\n",
    "        ‚Üì\n",
    "  Respuesta Final\n",
    "```\n",
    "\n",
    "### Modelos Utilizados\n",
    "\n",
    "| Componente | Modelo | Justificaci√≥n |\n",
    "|------------|--------|---------------|\n",
    "| Embeddings | [nombre] | [por qu√© elegiste este] |\n",
    "| Clasificaci√≥n | [nombre] | [por qu√© elegiste este] |\n",
    "| Generaci√≥n | [nombre] | [por qu√© elegiste este] |\n",
    "\n",
    "### Decisiones de Dise√±o\n",
    "\n",
    "1. **[Decisi√≥n 1]**: [Explicaci√≥n]\n",
    "2. **[Decisi√≥n 2]**: [Explicaci√≥n]\n",
    "3. **[Decisi√≥n 3]**: [Explicaci√≥n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç An√°lisis de Resultados\n",
    "\n",
    "### Fortalezas del Sistema\n",
    "\n",
    "1. **[Fortaleza 1]**: [Descripci√≥n y evidencia]\n",
    "2. **[Fortaleza 2]**: [Descripci√≥n y evidencia]\n",
    "3. **[Fortaleza 3]**: [Descripci√≥n y evidencia]\n",
    "\n",
    "### Limitaciones Identificadas\n",
    "\n",
    "1. **[Limitaci√≥n 1]**: [Descripci√≥n y posible soluci√≥n]\n",
    "2. **[Limitaci√≥n 2]**: [Descripci√≥n y posible soluci√≥n]\n",
    "3. **[Limitaci√≥n 3]**: [Descripci√≥n y posible soluci√≥n]\n",
    "\n",
    "### Mejoras Futuras\n",
    "\n",
    "1. **Corto plazo**:\n",
    "   - [Mejora 1]\n",
    "   - [Mejora 2]\n",
    "\n",
    "2. **Largo plazo**:\n",
    "   - [Mejora 1]\n",
    "   - [Mejora 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Aprendizajes y Conclusiones\n",
    "\n",
    "### Principales Aprendizajes\n",
    "\n",
    "1. **T√©cnico**:\n",
    "   - [Aprendizaje t√©cnico 1]\n",
    "   - [Aprendizaje t√©cnico 2]\n",
    "\n",
    "2. **Conceptual**:\n",
    "   - [Aprendizaje conceptual 1]\n",
    "   - [Aprendizaje conceptual 2]\n",
    "\n",
    "3. **Pr√°ctico**:\n",
    "   - [Aprendizaje pr√°ctico 1]\n",
    "   - [Aprendizaje pr√°ctico 2]\n",
    "\n",
    "### Reflexi√≥n Final\n",
    "\n",
    "[Escribe un p√°rrafo reflexionando sobre:\n",
    "- Lo que aprendiste en el curso\n",
    "- C√≥mo aplicar√≠as estos conocimientos\n",
    "- Pr√≥ximos pasos en tu aprendizaje de NLP/LLMs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üì¶ Secci√≥n 9: Empaquetado y Entrega\n",
    "\n",
    "Antes de entregar tu proyecto, aseg√∫rate de:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist Final\n",
    "\n",
    "Marca cada item cuando est√© completado:\n",
    "\n",
    "### C√≥digo\n",
    "- [ ] Todos los ejercicios est√°n completados\n",
    "- [ ] El c√≥digo ejecuta sin errores\n",
    "- [ ] Las funciones tienen documentaci√≥n (docstrings)\n",
    "- [ ] El c√≥digo est√° comentado apropiadamente\n",
    "- [ ] Se siguen buenas pr√°cticas de programaci√≥n\n",
    "\n",
    "### Componentes\n",
    "- [ ] ‚úÖ Preprocesamiento NLP cl√°sico implementado\n",
    "- [ ] ‚úÖ Sistema de embeddings y b√∫squeda sem√°ntica funcional\n",
    "- [ ] ‚úÖ Clasificador con BERT implementado y evaluado\n",
    "- [ ] ‚úÖ Sistema RAG completo funcionando\n",
    "- [ ] ‚úÖ Generador de texto implementado\n",
    "- [ ] ‚úÖ Agente integrador creado\n",
    "\n",
    "### Documentaci√≥n\n",
    "- [ ] Secci√≥n 0 completada (definici√≥n del proyecto)\n",
    "- [ ] Demo completa funcional\n",
    "- [ ] Arquitectura documentada\n",
    "- [ ] An√°lisis de resultados incluido\n",
    "- [ ] Conclusiones y aprendizajes escritos\n",
    "\n",
    "### Entrega\n",
    "- [ ] Notebook ejecuta completamente en Colab\n",
    "- [ ] Todas las celdas producen output esperado\n",
    "- [ ] Enlace de Colab o repo de GitHub preparado\n",
    "- [ ] README.md creado (si usas GitHub)\n",
    "\n",
    "### Calidad\n",
    "- [ ] C√≥digo limpio y organizado\n",
    "- [ ] Visualizaciones claras y √∫tiles\n",
    "- [ ] Ejemplos demostrativos incluidos\n",
    "- [ ] M√©tricas de evaluaci√≥n calculadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì§ Instrucciones de Entrega Final\n",
    "\n",
    "### Si usas Google Colab:\n",
    "\n",
    "1. Ejecuta todas las celdas: `Entorno de ejecuci√≥n ‚Üí Ejecutar todas`\n",
    "2. Verifica que no haya errores\n",
    "3. Guarda: `Archivo ‚Üí Guardar una copia en Drive`\n",
    "4. Comparte: Click en `Compartir` ‚Üí `Cualquier persona con el enlace`\n",
    "5. Copia el enlace y env√≠alo\n",
    "\n",
    "### Si usas GitHub:\n",
    "\n",
    "1. Crea un repositorio nuevo\n",
    "2. A√±ade este notebook\n",
    "3. Crea un README.md con:\n",
    "   - T√≠tulo del proyecto\n",
    "   - Descripci√≥n breve\n",
    "   - Instrucciones de instalaci√≥n\n",
    "   - Instrucciones de uso\n",
    "   - Ejemplos de resultados\n",
    "   - Cr√©ditos y referencias\n",
    "4. Sube el c√≥digo: `git add . && git commit -m \"Proyecto final\" && git push`\n",
    "5. Comparte el enlace del repositorio\n",
    "\n",
    "### Informaci√≥n a incluir en la entrega:\n",
    "\n",
    "- **Nombre**: [Tu nombre]\n",
    "- **T√≠tulo del proyecto**: [T√≠tulo]\n",
    "- **Enlace**: [URL de Colab o GitHub]\n",
    "- **Opci√≥n elegida**: [A, B, C, o D]\n",
    "- **Tiempo invertido**: [Aproximadamente X horas]\n",
    "- **Comentarios adicionales**: [Opcional]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéâ ¬°Felicitaciones!\n",
    "\n",
    "Si has llegado hasta aqu√≠, has completado el desaf√≠o final del curso de NLP y LLMs.\n",
    "\n",
    "Has construido un sistema completo que integra:\n",
    "- T√©cnicas cl√°sicas de NLP\n",
    "- Modelos de lenguaje modernos\n",
    "- Arquitecturas transformer (BERT, GPT)\n",
    "- Sistemas avanzados (RAG, Agentes)\n",
    "\n",
    "## üöÄ Pr√≥ximos Pasos\n",
    "\n",
    "Para continuar tu aprendizaje:\n",
    "\n",
    "1. **Expande tu proyecto**:\n",
    "   - A√±ade m√°s fuentes de datos\n",
    "   - Implementa una interfaz web (Gradio, Streamlit)\n",
    "   - Fine-tunea modelos en tu dominio espec√≠fico\n",
    "\n",
    "2. **Explora nuevos temas**:\n",
    "   - Modelos multimodales (CLIP, BLIP)\n",
    "   - LLMs m√°s grandes (Llama, Mistral)\n",
    "   - T√©cnicas de optimizaci√≥n (LoRA, quantizaci√≥n)\n",
    "\n",
    "3. **Comparte y colabora**:\n",
    "   - Publica tu proyecto en GitHub\n",
    "   - Escribe un blog post sobre lo aprendido\n",
    "   - Contribuye a proyectos open source\n",
    "\n",
    "## üìö Recursos Adicionales\n",
    "\n",
    "- [Hugging Face Course](https://huggingface.co/course)\n",
    "- [Papers with Code](https://paperswithcode.com/)\n",
    "- [Andrej Karpathy - Neural Networks](https://karpathy.ai/)\n",
    "- [Sebastian Ruder - NLP Blog](https://ruder.io/)\n",
    "\n",
    "---\n",
    "\n",
    "**¬°Mucho √©xito con tu proyecto y tu carrera en NLP!** üéì‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
